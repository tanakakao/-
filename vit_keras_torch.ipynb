{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1LZQDZHfA6fujV6EBlUaxLAlaD1aReTe4",
      "authorship_tag": "ABX9TyNqyeOuOIDA2/8a7ZJs4tI0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanakakao/studymemo/blob/main/vit_keras_torch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "Fl2Y9pSxG7Sb",
        "outputId": "a93469a0-ec4c-40b4-bec6-bdc628ae8e65"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-e13e5be3fee8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-2-e13e5be3fee8>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x216 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Layer, Input, Dense, Conv1D, Conv2D, Activation, Dropout, LayerNormalization, Reshape, MultiHeadAttention, RepeatVector, Concatenate\n",
        "from tensorflow.keras import activations\n",
        "from tensorflow.keras.optimizers import RMSprop, Adagrad, Adam\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        " \n",
        "from keras import backend as K\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import time\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import cifar10\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "# データセットの読み込み\n",
        "#(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# バッチサイズ、クラス数、エポック数の設定\n",
        "#batch_size=32\n",
        "#num_classes=10\n",
        "#epochs=5\n",
        "\n",
        "# データリサイズ\n",
        "#img_rows=224\n",
        "#img_cols=224\n",
        "\n",
        "#x_train = np.array([cv2.resize(img, (img_rows,img_cols)) for img in x_train[::5,:,:,:]])\n",
        "#x_test = np.array([cv2.resize(img, (img_rows,img_cols)) for img in x_test[::5,:,:,:]])\n",
        "\n",
        "# データ正規化\n",
        "#x_train=x_train.astype('float32')\n",
        "#x_train/=255\n",
        "#x_test=x_test.astype('float32')\n",
        "#x_test/=255\n",
        "\n",
        "# one-hotベクトル化\n",
        "#y_train = y_train[::5]\n",
        "#y_test = y_test[::5]\n",
        "#y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "#y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "fig, axes = plt.subplots(1, 4, figsize=(12,3))\n",
        "[axes[i].imshow(x_train[i]) for i in range(4)];"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(len(os.listdir(\"/content/drive/MyDrive/PetImages/train/Dog\")))\n",
        "print(len(os.listdir(\"/content/drive/MyDrive/PetImages/train/Cat\")))\n",
        "print(len(os.listdir(\"/content/drive/MyDrive/PetImages/val/Dog\")))\n",
        "print(len(os.listdir(\"/content/drive/MyDrive/PetImages/val/Cat\")))\n",
        "print(len(os.listdir(\"/content/drive/MyDrive/PetImages/test/Dog\")))\n",
        "print(len(os.listdir(\"/content/drive/MyDrive/PetImages/test/Cat\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iehEOJsVQCt-",
        "outputId": "2174a971-5c07-41c7-ead9-4a5da940a2fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7000\n",
            "7000\n",
            "3000\n",
            "3000\n",
            "621\n",
            "2396\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "#!unzip kagglecatsanddogs_5340.zip\n",
        "#!cp -rp \"PetImages\" \"/content/drive/My Drive/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLMA1Yz-QvUd",
        "outputId": "beee5fba-0428-4ffb-c2fe-c08403cb40ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open kagglecatsanddogs_5340.zip, kagglecatsanddogs_5340.zip.zip or kagglecatsanddogs_5340.zip.ZIP.\n",
            "cp: cannot stat 'PetImages': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('/content/drive/MyDrive/PetImages/train/Dog', exist_ok=True)\n",
        "os.makedirs('/content/drive/MyDrive/PetImages/train/Cat', exist_ok=True)\n",
        "os.makedirs('/content/drive/MyDrive/PetImages/val/Dog', exist_ok=True)\n",
        "os.makedirs('/content/drive/MyDrive/PetImages/val/Cat', exist_ok=True)\n",
        "os.makedirs('/content/drive/MyDrive/PetImages/test/Dog', exist_ok=True)\n",
        "os.makedirs('/content/drive/MyDrive/PetImages/test/Cat', exist_ok=True)"
      ],
      "metadata": {
        "id": "N2VB-KUUXzPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for i in range(12001,13001)[::-1]:\n",
        "  try:\n",
        "    shutil.move(\"/content/drive/MyDrive/PetImages/Cat/\"+str(i)+\".jpg\", '/content/drive/MyDrive/PetImages/test/Cat')\n",
        "  except:\n",
        "    continue\n",
        "  try:\n",
        "    shutil.move(\"/content/drive/MyDrive/PetImages/Dog/\"+str(i)+\".jpg\", '/content/drive/MyDrive/PetImages/test/Dog')\n",
        "  except:\n",
        "    continue\n",
        "  #if len(os.listdir(\"/content/drive/MyDrive/PetImages/val/Dog\"))==3000:\n",
        "  #  break"
      ],
      "metadata": {
        "id": "zWToWxGDXZxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Layer, Input, Dense, Conv1D, Conv2D, Activation, Dropout, LayerNormalization, Reshape, RepeatVector, Concatenate\n",
        "from tensorflow.keras import activations\n",
        "from tensorflow.keras.optimizers import RMSprop, Adagrad, Adam\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler, ReduceLROnPlateau, ModelCheckpoint\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        " \n",
        "from keras import backend as K\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import time\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import cifar10\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2"
      ],
      "metadata": {
        "id": "2JSHpUC9U-B4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class patch_embbeding(Layer):\n",
        "    def __init__(self, img_size, patch_size=4, hidden_dim=8):\n",
        "        super().__init__()\n",
        "        self.D = hidden_dim\n",
        "        \n",
        "        self.patch_conv = Conv2D(filters = hidden_dim, kernel_size = (patch_size,patch_size), strides=patch_size, padding = 'same', activation='gelu')\n",
        "        \n",
        "        # [class]追加\n",
        "        self.cls_token = self.add_weight(\n",
        "            shape=(1,1,hidden_dim), initializer=\"random_normal\", trainable=True, name='class', dtype=tf.float32\n",
        "        )\n",
        "\n",
        "        # position encoding\n",
        "        self.position = self.add_weight(\n",
        "            shape=(int(img_size[0]*img_size[1]/(patch_size*patch_size))+1,self.D), initializer=\"random_normal\", trainable=True, name='position', dtype=tf.float32\n",
        "        )\n",
        "        \n",
        "        self.repeat = RepeatVector\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        out = self.patch_conv(inputs)\n",
        "        out = Reshape((-1,self.D))(out)\n",
        "        cls = tf.broadcast_to(self.cls_token, [batch_size, 1, self.D])\n",
        "        out = Concatenate(axis=1)([cls, out])\n",
        "        out = out+self.position \n",
        "        return out\n",
        "\n",
        "class SelfMultiHeadAttention(Layer):\n",
        "    '''\n",
        "    Multi-Head Attentionレイヤ\n",
        "\n",
        "    model = MultiheadAttention(\n",
        "        hidden_dim = 512,\n",
        "        head_num = 8,\n",
        "        drop_rate = 0.5\n",
        "    )\n",
        "    '''\n",
        "    def __init__(self, hidden_dim, heads_num, drop_rate=0.5):\n",
        "        '''\n",
        "        Multi-Head Attentionレイヤ\n",
        "    \n",
        "        hidden_dim : Embeddingされた単語ベクトルの長さ\n",
        "        heads_num : マルチヘッドAttentionのヘッド数\n",
        "           ※hidden_numはheads_numで割り切れえる値とすること\n",
        "        drop_rate : 出力のDropout率\n",
        "        '''\n",
        "\n",
        "        super(SelfMultiHeadAttention, self).__init__()\n",
        "        # 入力の線形変換\n",
        "        # 重み行列は[hidden_dim, hidden_dim]\n",
        "        self.query = Conv1D(hidden_dim, kernel_size=1)\n",
        "        self.key   = Conv1D(hidden_dim, kernel_size=1)\n",
        "        self.value = Conv1D(hidden_dim, kernel_size=1)\n",
        "        \n",
        "        # 出力の線形変換\n",
        "        self.projection = Conv1D(hidden_dim, kernel_size=1)\n",
        "        \n",
        "        # 出力のDropout\n",
        "        self.drop = Dropout(drop_rate)\n",
        "        \n",
        "        self.nf = hidden_dim\n",
        "        self.nh = heads_num\n",
        "    \n",
        "    def atten(self, query, key, value, attention_mask, training):\n",
        "        \"\"\"\n",
        "        Attention\n",
        "        \n",
        "        query, key, value : クエリ、キー、バリュー\n",
        "            query [batch_size, head_num, q_length, hidden_dim//head_num]\n",
        "            key, value [batch_size, head_num, m_length, hidden_dim//head_num]\n",
        "            ただし、encoder:q_length=m_length\n",
        "                   decoder:mask multihead attentionではq_length=m_length\n",
        "                           2つ目のmultihead attentionではq_length≠m_length\n",
        "        attention_mask : attention weight に適用される mask\n",
        "            encoder : [1, 1, q_length, q_length]\n",
        "            decoder : [1, 1, m_length, m_length]\n",
        "        \"\"\"\n",
        "        # 各値を取得\n",
        "        shape = query.shape.as_list() # batch_size, head_num, q_length, hidden_dim//head_num\n",
        "        batch_size = -1 if shape[0] is None else shape[0]\n",
        "        token_num = shape[2] # トークン列数(q_length)\n",
        "        hidden_dim = shape[1]*shape[3] # 特徴ベクトルの長さ(head_num × hidden_dim//head_num = hidden_dim)\n",
        "        \n",
        "        # ここで q と k の内積を取ることで、query と key の単語間の関連度のようなものを計算します。\n",
        "        # tf.matmulで最後の2成分について積を計算(それ以外は形がそろっている必要あり)\n",
        "        # transpose_bで転置\n",
        "        # [batch_size, head_num, q_length, hidden_dim/head_num] @ [batch_size, head_num, hidden_dim/head_num, m_length] = [batch_size, head_num, q_length, m_length]\n",
        "        scores = tf.matmul(query, key, transpose_b=True)\n",
        "        \n",
        "        # scoreをhidden_dimの平方根割る\n",
        "        scores = tf.multiply(scores, tf.math.rsqrt(tf.cast(hidden_dim, tf.float32)))\n",
        "        \n",
        "        # Attention Maskがあればscoreに加算\n",
        "        # attention_mask: [1, 1, (q|m)_length, (q|m)_length] \n",
        "        # マスク(参照しない部分)の場所に1、使用する部分は0とする\n",
        "        # 1の部分を -無限大にする(softmax(-無限大)=0となる)\n",
        "        # 1. PADを無視\n",
        "        # 2. DecoderのSelf-Attentionで未来の情報を参照できないようにする\n",
        "        if attention_mask is not None:\n",
        "            scores = scores + attention_mask * -1e9\n",
        "        # softmax を取ることで正規化します\n",
        "        # input(query) の各単語に対して memory(key) の各単語のどこから情報を引いてくるかの重み\n",
        "        atten_weight = tf.nn.softmax(scores, axis=-1)\n",
        "        \n",
        "        # 重みに従って value から情報を引いてきます\n",
        "        # [batch_size, head_num, q_length, m_length] @ [batch_size, head_num, m_length, hidden_dim/head_num] = [batch_size, head_num, q_length, hidden_dim/head_num]\n",
        "        # input(query) の単語ごとに memory(value)の各単語 に attention_weight を掛け合わせて足し合わせた ベクトル(分散表現の重み付き和)を計算\n",
        "        context = tf.matmul(atten_weight, value)\n",
        "        \n",
        "        # 各ヘッドの結合(reshape)\n",
        "        # 入力と同じ形に変換する\n",
        "        # [batch_size, head_num, q_length, hidden_dim/head_num] -> [batch_size, q_length, head_num, hidden_dim/head_num]\n",
        "        context = tf.transpose(context, [0, 2, 1, 3])\n",
        "        # [batch_size, q_length, head_num, hidden_dim/head_num] -> [batch_size, q_length, hidden_dim]\n",
        "        context = tf.reshape(context, (batch_size, token_num, hidden_dim))\n",
        "        \n",
        "        # 線形変換\n",
        "        context = self.projection(context, training=training)\n",
        "        \n",
        "        return self.drop(context, training=training), atten_weight\n",
        "\n",
        "    def _split(self, x):\n",
        "        \"\"\"\n",
        "        query, key, valueを分割する\n",
        "        \n",
        "        入力 shape: [batch_size, length, hidden_dim]\n",
        "        出力 shape: [batch_size, head_num, length, hidden_dim//head_num]\n",
        "        \"\"\"\n",
        "        # 各値を取得\n",
        "        hidden_dim = self.nf\n",
        "        heads_num = self.nh\n",
        "        shape = x.shape.as_list()\n",
        "        batch_size = -1 if shape[0] is None else shape[0]\n",
        "        token_num = shape[1] # トークン列数\n",
        "        \n",
        "        # [batch_size, (q|m)_length, hidden_dim] -> [batch_size, (q|m)_length, head_num, hidden_dim/head_num]\n",
        "        # splitだが実際は次元を拡張する処理\n",
        "        x = tf.reshape(x, (batch_size, token_num, heads_num, int(hidden_dim/heads_num)))\n",
        "        \n",
        "        # [batch_size, (q|m)_length, head_num, hidden_dim/head_num] -> [batch_size, head_num, (q|m)_length, hidden_dim/head_num]\n",
        "        x = tf.transpose(x, [0, 2, 1, 3])\n",
        "        return x\n",
        "    \n",
        "    def call(self, x, training, memory, attention_mask=None, return_attention_scores=False):\n",
        "        \"\"\"\n",
        "        モデルの実行\n",
        "        \n",
        "        input : 入力(query) [batch_size, length, hidden_dim]\n",
        "        memory : 入力(key, value) [batch_size, length, hidden_dim]\n",
        "        　※memory(key, value)についてはqueryのtoken_numと異なる場合がある\n",
        "        attention_mask : attention weight に適用される mask\n",
        "            [batch_size, 1, q_length, k_length] \n",
        "            pad 等無視する部分が 1 となるようなもの(Decoderで使用)\n",
        "        return_attention_scores : attention weightを出力するか\n",
        "        \"\"\"\n",
        "        # memoryが入力されない場合、memory=input(Self Attention)とする\n",
        "        if memory is None:\n",
        "            memory = x\n",
        "\n",
        "        # input -> query\n",
        "        # memory -> key, value\n",
        "        # [batch_size, (q|m)_length, hidden_dim] @ [hidden_dim, hidden_dim] -> [batch_size, (q|m)_length, hidden_dim] \n",
        "        query = self.query(x)\n",
        "        key = self.key(memory)\n",
        "        value = self.value(memory)\n",
        "        \n",
        "        # ヘッド数に分割する\n",
        "        # 実際はreshapeで次数を1つ増やす\n",
        "        # [batch_size, (q|m)_length, hidden_dim] -> [batch_size, head_num, (q|m)_length, hidden_dim/head_num]\n",
        "        query = self._split(query)\n",
        "        key = self._split(key)\n",
        "        value = self._split(value)\n",
        "        \n",
        "        # attention\n",
        "        # 入力と同じ形の出力\n",
        "        # context: [batch_size, q_length, hidden_dim]\n",
        "        # score_weightsはEncoderではNoneとする\n",
        "        context, attn_weights = self.atten(query, key, value, attention_mask, training)\n",
        "        if not return_attention_scores:\n",
        "            return context\n",
        "        else:\n",
        "            return context, attn_weights\n",
        "\n",
        "class FeedForwardNetwork(Layer):\n",
        "    '''\n",
        "    Position-wise Feedforward Neural Network\n",
        "    transformer blockで使用される全結合層\n",
        "    '''\n",
        "    def __init__(self, hidden_dim, drop_rate):\n",
        "        '''\n",
        "        hidden_dim : Embeddingされた単語ベクトルの長さ\n",
        "        drop_rate : 出力のDropout率\n",
        "        '''\n",
        "        super().__init__()\n",
        "        # 2層構造\n",
        "        # 1層目：チャンネル数を増加させる\n",
        "        self.filter_dense_layer = Dense(hidden_dim * 4, use_bias=True, activation='gelu')\n",
        "        \n",
        "        # 2層目：元のチャンネル数に戻す\n",
        "        self.output_dense_layer = Dense(hidden_dim, use_bias=True)\n",
        "        self.drop = Dropout(drop_rate)\n",
        "\n",
        "    def call(self, x, training):\n",
        "        '''\n",
        "        入力と出力で形が変わらない\n",
        "        x : 入力 [batch_size, length, hidden_dim]\n",
        "        '''\n",
        "        \n",
        "        # [batch_size, (q|m)_length, hidden_dim] -> [batch_size, (q|m)_length, 4*hidden_dim]\n",
        "        x = self.filter_dense_layer(x)\n",
        "        x = self.drop(x, training=training)\n",
        "        \n",
        "        # [batch_size, (q|m)_length, 4*hidden_dim] -> [batch_size, (q|m)_length, hidden_dim]\n",
        "        return self.output_dense_layer(x)\n",
        "\n",
        "class ResidualNormalizationWrapper(Layer):\n",
        "    '''\n",
        "    残差接続\n",
        "    output: input + SubLayer(input)\n",
        "    '''\n",
        "    def __init__(self, layer, drop_rate):\n",
        "        '''\n",
        "        layer : 残渣接続したいレイヤ(MultiHeadAttentionかFeedForwardNetwork)に適用\n",
        "        drop_rate : 出力のDropout率\n",
        "        '''\n",
        "        super().__init__()\n",
        "        self.layer = layer # SubLayer : ここではAttentionかFFN\n",
        "        self.layer_normalization = LayerNormalization()\n",
        "        self.drop = Dropout(drop_rate)\n",
        "\n",
        "    def call(self, x, training, memory=None, attention_mask=None, return_attention_scores=None):\n",
        "        \"\"\"\n",
        "        モデルの実行\n",
        "        \n",
        "        memory : 入力(key, value) [batch_size, length, hidden_dim]\n",
        "        　※memory(key, value)についてはqueryのlengthと異なる場合がある\n",
        "        attention_mask : attention weight に適用される mask\n",
        "            [batch_size, 1, q_length, q_length] \n",
        "            pad 等無視する部分が 1 となるようなもの(Decoderで使用)\n",
        "        return_attention_scores : attention weightを出力するか\n",
        "\n",
        "        AttentionもFFNも入力と出力で形が変わらない\n",
        "        output : [batch_size, length, hidden_dim]\n",
        "        \"\"\"\n",
        "        \n",
        "        params = {}\n",
        "        if memory is not None:\n",
        "            params['memory'] = memory\n",
        "        if attention_mask is not None:\n",
        "            params['attention_mask'] = attention_mask\n",
        "        if return_attention_scores:\n",
        "            params['return_attention_scores'] = return_attention_scores\n",
        "        \n",
        "        out = self.layer_normalization(x)\n",
        "        if return_attention_scores:\n",
        "            # attention weightを返す\n",
        "            out, attn_weights = self.layer(out, training, **params)\n",
        "            out = self.drop(out, training=training)\n",
        "            return x + out, attn_weights\n",
        "        else:\n",
        "            # attention weightを返さない\n",
        "            out = self.layer(out, training, **params)\n",
        "            out = self.drop(out, training=training)\n",
        "            return x + out\n",
        "\n",
        "class EncoderLayer(Layer):\n",
        "    \"\"\"\n",
        "    Encoderレイヤ\n",
        "    　MultiHeadAttentionとFeedForwardNetworkの組み合わせ\n",
        "      それぞれ残差接続されている\n",
        "    \"\"\"\n",
        "    def __init__(self, hidden_dim, heads_num, drop_rate=0.2):\n",
        "        \"\"\"\n",
        "        hidden_dim : Embeddingされた単語ベクトルの長さ\n",
        "        heads_num : Multi-head Attentionのヘッド数\n",
        "           ※hidden_numはheads_numで割り切れえる値とすること\n",
        "        drop_rate : 出力のDropout率\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        # Multi-head attention\n",
        "        self.atten = ResidualNormalizationWrapper(\n",
        "            layer = SelfMultiHeadAttention(hidden_dim = hidden_dim,\n",
        "                                           heads_num = heads_num,\n",
        "                                           drop_rate = drop_rate),\n",
        "            drop_rate = drop_rate)\n",
        "        \n",
        "        # Feed Forward Network\n",
        "        self.ffn = ResidualNormalizationWrapper(\n",
        "            layer = FeedForwardNetwork(hidden_dim = hidden_dim,\n",
        "                                       drop_rate = drop_rate),\n",
        "            drop_rate = drop_rate)\n",
        "    \n",
        "    def call(self, input, training, memory, attention_mask=None, return_attention_scores=False):\n",
        "        \"\"\"\n",
        "        x : 入力(query) [batch_size, length, hidden_dim]\n",
        "        memory : 入力(key, value) [batch_size, length, hidden_dim]\n",
        "        　※memory(key, value)についてはqueryのtoken_numと異なる場合がある\n",
        "        attention_mask : attention weight に適用される mask\n",
        "            [batch_size, 1, q_length, k_length] \n",
        "            pad 等無視する部分が 1 となるようなもの(Decoderで使用)\n",
        "        return_attention_scores : attention weightを出力するか\n",
        "\n",
        "        AttentionもFFNも入力と出力で形が変わらない\n",
        "        output : [batch_size, length, hidden_dim]\n",
        "        \n",
        "        入力と出力で形式が変わらない\n",
        "        output : [batch_size, length, hidden_dim]\n",
        "        \"\"\"\n",
        "        \n",
        "        if return_attention_scores:\n",
        "            x, attn_weights = self.atten(input,training, memory, attention_mask, return_attention_scores)\n",
        "            x = self.ffn(x)\n",
        "            return x, attn_weights\n",
        "        else:\n",
        "            x = self.atten(input, training, memory, attention_mask, return_attention_scores)\n",
        "            x = self.ffn(x)\n",
        "            return x\n",
        "\n",
        "class Encoder(Layer):\n",
        "    '''\n",
        "    TransformerのEncoder\n",
        "    '''\n",
        "    def __init__(self, img_size, patch_size, hopping_num, heads_num, hidden_dim, drop_rate):\n",
        "        '''\n",
        "        hopping_num : Multi-head Attentionの繰り返し数\n",
        "        hidden_dim : Embeddingされた特徴ベクトルの長さ\n",
        "        heads_num : Multi-head Attentionのヘッド数\n",
        "           ※hidden_numはheads_numで割り切れえる値とすること\n",
        "        drop_rate : 出力のDropout率\n",
        "        '''\n",
        "        super().__init__()\n",
        "        self.hopping_num = hopping_num\n",
        "        \n",
        "        # Position Embedding\n",
        "        self.patch_embbeding = patch_embbeding(img_size=img_size, patch_size=patch_size, hidden_dim=hidden_dim)\n",
        "        self.input_dropout_layer = Dropout(drop_rate)\n",
        "\n",
        "        # Multi-head Attentionの繰り返し(hopping)のリスト\n",
        "        self.attention_block_list = [EncoderLayer(hidden_dim, heads_num) for _ in range(hopping_num)]\n",
        "        self.output_normalization = LayerNormalization()\n",
        "\n",
        "    def call(self, input, training, attention_mask=None, return_attention_scores=False):\n",
        "        '''\n",
        "        input: 入力 [batch_size, q_length, hidden_dim]\n",
        "        memory: 入力 [batch_size, m_length, hidden_dim]\n",
        "        attention_mask: attention weight に適用される mask\n",
        "            [batch_size, 1, q_length, q_length] \n",
        "            pad 等無視する部分が 0 となるようなもの(Decoderで使用)\n",
        "        return_attention_scores : attention weightを出力するか\n",
        "        出力 [batch_size, q_length, hidden_dim]\n",
        "        '''\n",
        "        # Positional Embedding\n",
        "        embedded_input = self.patch_embbeding(input)\n",
        "        query = self.input_dropout_layer(embedded_input, training=training)\n",
        "\n",
        "        # Encoderレイヤを繰り返し適用\n",
        "        if return_attention_scores:\n",
        "            for i in range(self.hopping_num):\n",
        "                query, atten_weights = self.attention_block_list[i](query, training, embedded_input, attention_mask, return_attention_scores)\n",
        "\n",
        "            # [batch_size, q_length, hidden_dim]\n",
        "            return self.output_normalization(query), atten_weights\n",
        "        else:\n",
        "            for i in range(self.hopping_num):\n",
        "                query = self.attention_block_list[i](query, training, embedded_input, attention_mask, return_attention_scores)\n",
        "                #print(query.shape)\n",
        "            # [batch_size, q_length, hidden_dim]\n",
        "            return self.output_normalization(query)\n",
        "\n",
        "class VisionTransformer(Model):\n",
        "    \"\"\"\n",
        "    Transformerベースの時系列予測モデル\n",
        "    \n",
        "    \"\"\"\n",
        "    def __init__(self, img_size, patch_size, hopping_num, heads_num, hidden_dim, drop_rate):\n",
        "        '''\n",
        "        hopping_num : Multi-head Attentionの繰り返し数\n",
        "        hidden_dim : Embeddingされた特徴ベクトルの長さ\n",
        "        heads_num : Multi-head Attentionのヘッド数\n",
        "           ※hidden_numはheads_numで割り切れえる値とすること\n",
        "        drop_rate : 出力のDropout率\n",
        "        '''\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(img_size, patch_size, hopping_num, heads_num, hidden_dim, drop_rate)\n",
        "        \n",
        "        # 全結合層\n",
        "        self.fc1 = Dense(16, activation='tanh')\n",
        "        self.dropout1 = Dropout(drop_rate)\n",
        "   \n",
        "        self.final_layer = Dense(1, activation='sigmoid')\n",
        "\n",
        "    def call(self, inputs, return_attention_scores=False):\n",
        "        '''\n",
        "        inputs: 入力(encoder, decoder)\n",
        "        return_attention_scores : attention weightを出力するか\n",
        "        '''\n",
        "        # Encoderの出力はDecoderへの入力(memory)となる\n",
        "        # enc_input : [batch_size, enc_length, hidden_dim]\n",
        "        if return_attention_scores:\n",
        "            enc_output, enc_atten_weights = self.encoder(inputs, attention_mask=None,return_attention_scores=return_attention_scores)\n",
        "        else:\n",
        "            enc_output = self.encoder(inputs, attention_mask=None,return_attention_scores=return_attention_scores)\n",
        "         \n",
        "        # [batch_size, dec_length, hidden_dim] -> [batch_size, dec_length]\n",
        "        class_output = enc_output[:,0,:]\n",
        "        \n",
        "        fc_output = self.fc1(class_output)\n",
        "        fc_output = self.dropout1(fc_output)\n",
        "        final_output = self.final_layer(fc_output)\n",
        "\n",
        "        if return_attention_scores:\n",
        "            return final_output, enc_atten_weights\n",
        "        else:\n",
        "            return final_output"
      ],
      "metadata": {
        "id": "gJN856T9HH9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=25\n",
        "epochs = 120\n",
        "initial_lrate = 0.001\n",
        "\n",
        "# Checkpoint -- ベストのモデルのみ保存\n",
        "modelCheckpoint = ModelCheckpoint(filepath = \"/content/drive/MyDrive/dogcat_mini/\",\n",
        "                                  monitor='val_accuracy',\n",
        "                                  verbose=1,\n",
        "                                  save_best_only=True,\n",
        "                                  save_weights_only=False, # 重みのみ保存\n",
        "                                  mode='max', # val_accuracyの場合\n",
        "                                  period=1)\n",
        "\n",
        "def decay(epoch, steps=50):\n",
        "    initial_lrate = 0.001\n",
        "    drop = 0.1\n",
        "    epochs_drop = 50\n",
        "    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
        "    if lrate <= 1e-6:\n",
        "      lrate=1e-6\n",
        "    return lrate\n",
        "\n",
        "sgd = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.99, weight_decay=0.1)\n",
        "\n",
        "lr_sc = LearningRateScheduler(decay, verbose=1)\n",
        "\n",
        "model = VisionTransformer(img_size=(224,224), patch_size=4, hopping_num=4, heads_num=2, hidden_dim=32, drop_rate=0.1)\n",
        "model.compile(loss=['binary_crossentropy'], optimizer=sgd,  metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "cH3ZqX0yHdWM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "outputId": "5d75adec-d642-4ca5-ec59-3e1e0fe87279"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-c82a1e36095c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mlr_sc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLearningRateScheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVisionTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhopping_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheads_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msgd\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'VisionTransformer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "img_height = 224\n",
        "img_width = 224\n",
        "\n",
        "classes = ['Dog', 'Cat']\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   horizontal_flip=True,\n",
        "                                   channel_shift_range=True,\n",
        "                                   zoom_range=[0.5, 2.0],\n",
        "                                   rotation_range=10,\n",
        "                                   height_shift_range = 0.1,\n",
        "                                   width_shift_range = 0.1,\n",
        "                                   fill_mode='nearest')\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/dogcat_mini/train',\n",
        "        target_size=(img_height, img_width),\n",
        "        color_mode = 'rgb', #グレー:'grayscale'\n",
        "        batch_size=batch_size,\n",
        "        classes = classes, \n",
        "        class_mode='binary',#2つ'binary' 3つ以上:'categorical'\n",
        "        save_format='jpeg'\n",
        ")\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/dogcat_mini/val',\n",
        "        target_size=(img_height, img_width),\n",
        "        batch_size=batch_size,\n",
        "        classes = classes, \n",
        "        class_mode='binary',\n",
        "        save_format='jpeg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yEXp8AMjYCW",
        "outputId": "75310997-218e-485f-e6af-e6cb6519309e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5000 images belonging to 2 classes.\n",
            "Found 2000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.build((None, 224, 224, 3))  # build with input shape.\n",
        "dummy_input = Input(shape=(224, 224, 3))  # declare without batch demension.\n",
        "model_summary = Model(inputs=[dummy_input], outputs=model.call(dummy_input))\n",
        "model_summary.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgeQrYzhy8SU",
        "outputId": "1ef5d98c-68c9-44ff-9f67-ff42fa5ba720"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " encoder_15 (Encoder)        (None, 3137, 32)          152864    \n",
            "                                                                 \n",
            " tf.__operators__.getitem_2   (None, 32)               0         \n",
            " (SlicingOpLambda)                                               \n",
            "                                                                 \n",
            " dense_138 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_252 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_139 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 153,409\n",
            "Trainable params: 153,409\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit(train_generator,\n",
        "                  #batch_size=batch_size,\n",
        "                  epochs=epochs,\n",
        "                  #steps_per_epoch=int(len(x_train)//batch_size),\n",
        "                  validation_data=validation_generator,\n",
        "                  #validation_steps=int(len(x_test)//batch_size),\n",
        "                  callbacks = [modelCheckpoint, lr_sc]\n",
        "                  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEfOR-NpHf9h",
        "outputId": "9df378ef-afe6-4cbf-8ace-d0b0c3264ce0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.7200 - accuracy: 0.4946\n",
            "Epoch 1: val_accuracy improved from -inf to 0.50000, saving model to /content/drive/MyDrive/dogcat_mini/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as patch_embbeding_1_layer_call_fn, patch_embbeding_1_layer_call_and_return_conditional_losses, dropout_18_layer_call_fn, dropout_18_layer_call_and_return_conditional_losses, layer_normalization_17_layer_call_fn while saving (showing 5 of 161). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200/200 [==============================] - 1928s 10s/step - loss: 0.7200 - accuracy: 0.4946 - val_loss: 0.6941 - val_accuracy: 0.5000 - lr: 0.0010\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 2/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.7130 - accuracy: 0.4962\n",
            "Epoch 2: val_accuracy improved from 0.50000 to 0.56950, saving model to /content/drive/MyDrive/dogcat_mini/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as patch_embbeding_1_layer_call_fn, patch_embbeding_1_layer_call_and_return_conditional_losses, dropout_18_layer_call_fn, dropout_18_layer_call_and_return_conditional_losses, layer_normalization_17_layer_call_fn while saving (showing 5 of 161). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200/200 [==============================] - 105s 524ms/step - loss: 0.7130 - accuracy: 0.4962 - val_loss: 0.6925 - val_accuracy: 0.5695 - lr: 0.0010\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 3/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.7100 - accuracy: 0.4994\n",
            "Epoch 3: val_accuracy did not improve from 0.56950\n",
            "200/200 [==============================] - 97s 484ms/step - loss: 0.7100 - accuracy: 0.4994 - val_loss: 0.7078 - val_accuracy: 0.5000 - lr: 0.0010\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 4/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.7043 - accuracy: 0.5030\n",
            "Epoch 4: val_accuracy improved from 0.56950 to 0.58550, saving model to /content/drive/MyDrive/dogcat_mini/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as patch_embbeding_1_layer_call_fn, patch_embbeding_1_layer_call_and_return_conditional_losses, dropout_18_layer_call_fn, dropout_18_layer_call_and_return_conditional_losses, layer_normalization_17_layer_call_fn while saving (showing 5 of 161). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200/200 [==============================] - 103s 514ms/step - loss: 0.7043 - accuracy: 0.5030 - val_loss: 0.6827 - val_accuracy: 0.5855 - lr: 0.0010\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 5/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.6908 - accuracy: 0.5396\n",
            "Epoch 5: val_accuracy improved from 0.58550 to 0.59300, saving model to /content/drive/MyDrive/dogcat_mini/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as patch_embbeding_1_layer_call_fn, patch_embbeding_1_layer_call_and_return_conditional_losses, dropout_18_layer_call_fn, dropout_18_layer_call_and_return_conditional_losses, layer_normalization_17_layer_call_fn while saving (showing 5 of 161). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200/200 [==============================] - 102s 509ms/step - loss: 0.6908 - accuracy: 0.5396 - val_loss: 0.6763 - val_accuracy: 0.5930 - lr: 0.0010\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 6/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.6823 - accuracy: 0.5672\n",
            "Epoch 6: val_accuracy improved from 0.59300 to 0.61000, saving model to /content/drive/MyDrive/dogcat_mini/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as patch_embbeding_1_layer_call_fn, patch_embbeding_1_layer_call_and_return_conditional_losses, dropout_18_layer_call_fn, dropout_18_layer_call_and_return_conditional_losses, layer_normalization_17_layer_call_fn while saving (showing 5 of 161). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200/200 [==============================] - 103s 513ms/step - loss: 0.6823 - accuracy: 0.5672 - val_loss: 0.6640 - val_accuracy: 0.6100 - lr: 0.0010\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 7/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.6774 - accuracy: 0.5738\n",
            "Epoch 7: val_accuracy did not improve from 0.61000\n",
            "200/200 [==============================] - 94s 471ms/step - loss: 0.6774 - accuracy: 0.5738 - val_loss: 0.6661 - val_accuracy: 0.5915 - lr: 0.0010\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 8/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.6687 - accuracy: 0.5886\n",
            "Epoch 8: val_accuracy improved from 0.61000 to 0.61350, saving model to /content/drive/MyDrive/dogcat_mini/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as patch_embbeding_1_layer_call_fn, patch_embbeding_1_layer_call_and_return_conditional_losses, dropout_18_layer_call_fn, dropout_18_layer_call_and_return_conditional_losses, layer_normalization_17_layer_call_fn while saving (showing 5 of 161). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200/200 [==============================] - 103s 515ms/step - loss: 0.6687 - accuracy: 0.5886 - val_loss: 0.6592 - val_accuracy: 0.6135 - lr: 0.0010\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 9/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.6622 - accuracy: 0.5940\n",
            "Epoch 9: val_accuracy did not improve from 0.61350\n",
            "200/200 [==============================] - 94s 468ms/step - loss: 0.6622 - accuracy: 0.5940 - val_loss: 0.6472 - val_accuracy: 0.6085 - lr: 0.0010\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 10/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.6610 - accuracy: 0.6012\n",
            "Epoch 10: val_accuracy improved from 0.61350 to 0.63050, saving model to /content/drive/MyDrive/dogcat_mini/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as patch_embbeding_1_layer_call_fn, patch_embbeding_1_layer_call_and_return_conditional_losses, dropout_18_layer_call_fn, dropout_18_layer_call_and_return_conditional_losses, layer_normalization_17_layer_call_fn while saving (showing 5 of 161). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200/200 [==============================] - 102s 511ms/step - loss: 0.6610 - accuracy: 0.6012 - val_loss: 0.6444 - val_accuracy: 0.6305 - lr: 0.0010\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 11/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.6583 - accuracy: 0.5982\n",
            "Epoch 11: val_accuracy did not improve from 0.63050\n",
            "200/200 [==============================] - 94s 467ms/step - loss: 0.6583 - accuracy: 0.5982 - val_loss: 0.6506 - val_accuracy: 0.6205 - lr: 0.0010\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 12/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.6598 - accuracy: 0.5936\n",
            "Epoch 12: val_accuracy did not improve from 0.63050\n",
            "200/200 [==============================] - 95s 474ms/step - loss: 0.6598 - accuracy: 0.5936 - val_loss: 0.6407 - val_accuracy: 0.6160 - lr: 0.0010\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 13/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.6583 - accuracy: 0.5994\n",
            "Epoch 13: val_accuracy did not improve from 0.63050\n",
            "200/200 [==============================] - 94s 471ms/step - loss: 0.6583 - accuracy: 0.5994 - val_loss: 0.6472 - val_accuracy: 0.6235 - lr: 0.0010\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 14/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.6532 - accuracy: 0.6068\n",
            "Epoch 14: val_accuracy did not improve from 0.63050\n",
            "200/200 [==============================] - 95s 475ms/step - loss: 0.6532 - accuracy: 0.6068 - val_loss: 0.6548 - val_accuracy: 0.5905 - lr: 0.0010\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 15/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.6554 - accuracy: 0.6038\n",
            "Epoch 15: val_accuracy improved from 0.63050 to 0.64200, saving model to /content/drive/MyDrive/dogcat_mini/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as patch_embbeding_1_layer_call_fn, patch_embbeding_1_layer_call_and_return_conditional_losses, dropout_18_layer_call_fn, dropout_18_layer_call_and_return_conditional_losses, layer_normalization_17_layer_call_fn while saving (showing 5 of 161). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200/200 [==============================] - 103s 514ms/step - loss: 0.6554 - accuracy: 0.6038 - val_loss: 0.6514 - val_accuracy: 0.6420 - lr: 0.0010\n",
            "\n",
            "Epoch 16: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 16/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.6560 - accuracy: 0.6038\n",
            "Epoch 16: val_accuracy did not improve from 0.64200\n",
            "200/200 [==============================] - 93s 465ms/step - loss: 0.6560 - accuracy: 0.6038 - val_loss: 0.6372 - val_accuracy: 0.6185 - lr: 0.0010\n",
            "\n",
            "Epoch 17: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 17/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.6516 - accuracy: 0.6072\n",
            "Epoch 17: val_accuracy did not improve from 0.64200\n",
            "200/200 [==============================] - 94s 469ms/step - loss: 0.6516 - accuracy: 0.6072 - val_loss: 0.6535 - val_accuracy: 0.5885 - lr: 0.0010\n",
            "\n",
            "Epoch 18: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 18/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.6535 - accuracy: 0.6034\n",
            "Epoch 18: val_accuracy did not improve from 0.64200\n",
            "200/200 [==============================] - 95s 472ms/step - loss: 0.6535 - accuracy: 0.6034 - val_loss: 0.6336 - val_accuracy: 0.6275 - lr: 0.0010\n",
            "\n",
            "Epoch 19: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 19/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.6491 - accuracy: 0.6126\n",
            "Epoch 19: val_accuracy did not improve from 0.64200\n",
            "200/200 [==============================] - 94s 471ms/step - loss: 0.6491 - accuracy: 0.6126 - val_loss: 0.6379 - val_accuracy: 0.6350 - lr: 0.0010\n",
            "\n",
            "Epoch 20: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 20/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.6477 - accuracy: 0.6166\n",
            "Epoch 20: val_accuracy did not improve from 0.64200\n",
            "200/200 [==============================] - 93s 466ms/step - loss: 0.6477 - accuracy: 0.6166 - val_loss: 0.6290 - val_accuracy: 0.6370 - lr: 0.0010\n",
            "\n",
            "Epoch 21: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 21/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.6487 - accuracy: 0.6172\n",
            "Epoch 21: val_accuracy did not improve from 0.64200\n",
            "200/200 [==============================] - 93s 466ms/step - loss: 0.6487 - accuracy: 0.6172 - val_loss: 0.6393 - val_accuracy: 0.6120 - lr: 0.0010\n",
            "\n",
            "Epoch 22: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 22/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.6430 - accuracy: 0.6206\n",
            "Epoch 22: val_accuracy did not improve from 0.64200\n",
            "200/200 [==============================] - 93s 466ms/step - loss: 0.6430 - accuracy: 0.6206 - val_loss: 0.6226 - val_accuracy: 0.6385 - lr: 0.0010\n",
            "\n",
            "Epoch 23: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 23/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.6427 - accuracy: 0.6192\n",
            "Epoch 23: val_accuracy did not improve from 0.64200\n",
            "200/200 [==============================] - 93s 464ms/step - loss: 0.6427 - accuracy: 0.6192 - val_loss: 0.6324 - val_accuracy: 0.6390 - lr: 0.0010\n",
            "\n",
            "Epoch 24: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 24/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.6445 - accuracy: 0.6234\n",
            "Epoch 24: val_accuracy did not improve from 0.64200\n",
            "200/200 [==============================] - 92s 457ms/step - loss: 0.6445 - accuracy: 0.6234 - val_loss: 0.6303 - val_accuracy: 0.6310 - lr: 0.0010\n",
            "\n",
            "Epoch 25: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 25/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.6367 - accuracy: 0.6302\n",
            "Epoch 25: val_accuracy did not improve from 0.64200\n",
            "200/200 [==============================] - 94s 471ms/step - loss: 0.6367 - accuracy: 0.6302 - val_loss: 0.6203 - val_accuracy: 0.6395 - lr: 0.0010\n",
            "\n",
            "Epoch 26: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 26/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.6395 - accuracy: 0.6292\n",
            "Epoch 26: val_accuracy improved from 0.64200 to 0.64750, saving model to /content/drive/MyDrive/dogcat_mini/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as patch_embbeding_1_layer_call_fn, patch_embbeding_1_layer_call_and_return_conditional_losses, dropout_18_layer_call_fn, dropout_18_layer_call_and_return_conditional_losses, layer_normalization_17_layer_call_fn while saving (showing 5 of 161). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200/200 [==============================] - 104s 519ms/step - loss: 0.6395 - accuracy: 0.6292 - val_loss: 0.6170 - val_accuracy: 0.6475 - lr: 0.0010\n",
            "\n",
            "Epoch 27: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 27/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.6342 - accuracy: 0.6382\n",
            "Epoch 27: val_accuracy improved from 0.64750 to 0.65300, saving model to /content/drive/MyDrive/dogcat_mini/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as patch_embbeding_1_layer_call_fn, patch_embbeding_1_layer_call_and_return_conditional_losses, dropout_18_layer_call_fn, dropout_18_layer_call_and_return_conditional_losses, layer_normalization_17_layer_call_fn while saving (showing 5 of 161). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200/200 [==============================] - 103s 513ms/step - loss: 0.6342 - accuracy: 0.6382 - val_loss: 0.6245 - val_accuracy: 0.6530 - lr: 0.0010\n",
            "\n",
            "Epoch 28: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 28/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.6339 - accuracy: 0.6380\n",
            "Epoch 28: val_accuracy improved from 0.65300 to 0.66100, saving model to /content/drive/MyDrive/dogcat_mini/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as patch_embbeding_1_layer_call_fn, patch_embbeding_1_layer_call_and_return_conditional_losses, dropout_18_layer_call_fn, dropout_18_layer_call_and_return_conditional_losses, layer_normalization_17_layer_call_fn while saving (showing 5 of 161). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200/200 [==============================] - 104s 520ms/step - loss: 0.6339 - accuracy: 0.6380 - val_loss: 0.6120 - val_accuracy: 0.6610 - lr: 0.0010\n",
            "\n",
            "Epoch 29: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 29/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.6243 - accuracy: 0.6494\n",
            "Epoch 29: val_accuracy improved from 0.66100 to 0.66750, saving model to /content/drive/MyDrive/dogcat_mini/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as patch_embbeding_1_layer_call_fn, patch_embbeding_1_layer_call_and_return_conditional_losses, dropout_18_layer_call_fn, dropout_18_layer_call_and_return_conditional_losses, layer_normalization_17_layer_call_fn while saving (showing 5 of 161). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200/200 [==============================] - 105s 522ms/step - loss: 0.6243 - accuracy: 0.6494 - val_loss: 0.6029 - val_accuracy: 0.6675 - lr: 0.0010\n",
            "\n",
            "Epoch 30: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 30/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.6262 - accuracy: 0.6416\n",
            "Epoch 30: val_accuracy did not improve from 0.66750\n",
            "200/200 [==============================] - 95s 475ms/step - loss: 0.6262 - accuracy: 0.6416 - val_loss: 0.6007 - val_accuracy: 0.6650 - lr: 0.0010\n",
            "\n",
            "Epoch 31: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 31/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.6205 - accuracy: 0.6526\n",
            "Epoch 31: val_accuracy improved from 0.66750 to 0.67200, saving model to /content/drive/MyDrive/dogcat_mini/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as patch_embbeding_1_layer_call_fn, patch_embbeding_1_layer_call_and_return_conditional_losses, dropout_18_layer_call_fn, dropout_18_layer_call_and_return_conditional_losses, layer_normalization_17_layer_call_fn while saving (showing 5 of 161). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200/200 [==============================] - 104s 520ms/step - loss: 0.6205 - accuracy: 0.6526 - val_loss: 0.5987 - val_accuracy: 0.6720 - lr: 0.0010\n",
            "\n",
            "Epoch 32: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 32/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.6109 - accuracy: 0.6548\n",
            "Epoch 32: val_accuracy did not improve from 0.67200\n",
            "200/200 [==============================] - 96s 477ms/step - loss: 0.6109 - accuracy: 0.6548 - val_loss: 0.6132 - val_accuracy: 0.6500 - lr: 0.0010\n",
            "\n",
            "Epoch 33: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 33/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.6192 - accuracy: 0.6508\n",
            "Epoch 33: val_accuracy did not improve from 0.67200\n",
            "200/200 [==============================] - 94s 470ms/step - loss: 0.6192 - accuracy: 0.6508 - val_loss: 0.5989 - val_accuracy: 0.6565 - lr: 0.0010\n",
            "\n",
            "Epoch 34: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 34/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.6093 - accuracy: 0.6634\n",
            "Epoch 34: val_accuracy improved from 0.67200 to 0.67900, saving model to /content/drive/MyDrive/dogcat_mini/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as patch_embbeding_1_layer_call_fn, patch_embbeding_1_layer_call_and_return_conditional_losses, dropout_18_layer_call_fn, dropout_18_layer_call_and_return_conditional_losses, layer_normalization_17_layer_call_fn while saving (showing 5 of 161). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200/200 [==============================] - 104s 517ms/step - loss: 0.6093 - accuracy: 0.6634 - val_loss: 0.5985 - val_accuracy: 0.6790 - lr: 0.0010\n",
            "\n",
            "Epoch 35: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 35/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5999 - accuracy: 0.6710\n",
            "Epoch 35: val_accuracy did not improve from 0.67900\n",
            "200/200 [==============================] - 94s 469ms/step - loss: 0.5999 - accuracy: 0.6710 - val_loss: 0.5948 - val_accuracy: 0.6760 - lr: 0.0010\n",
            "\n",
            "Epoch 36: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 36/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.6130 - accuracy: 0.6576\n",
            "Epoch 36: val_accuracy improved from 0.67900 to 0.68500, saving model to /content/drive/MyDrive/dogcat_mini/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as patch_embbeding_1_layer_call_fn, patch_embbeding_1_layer_call_and_return_conditional_losses, dropout_18_layer_call_fn, dropout_18_layer_call_and_return_conditional_losses, layer_normalization_17_layer_call_fn while saving (showing 5 of 161). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200/200 [==============================] - 105s 526ms/step - loss: 0.6130 - accuracy: 0.6576 - val_loss: 0.5874 - val_accuracy: 0.6850 - lr: 0.0010\n",
            "\n",
            "Epoch 37: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 37/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.6026 - accuracy: 0.6678\n",
            "Epoch 37: val_accuracy improved from 0.68500 to 0.68750, saving model to /content/drive/MyDrive/dogcat_mini/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as patch_embbeding_1_layer_call_fn, patch_embbeding_1_layer_call_and_return_conditional_losses, dropout_18_layer_call_fn, dropout_18_layer_call_and_return_conditional_losses, layer_normalization_17_layer_call_fn while saving (showing 5 of 161). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200/200 [==============================] - 107s 533ms/step - loss: 0.6026 - accuracy: 0.6678 - val_loss: 0.5909 - val_accuracy: 0.6875 - lr: 0.0010\n",
            "\n",
            "Epoch 38: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 38/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.6015 - accuracy: 0.6674\n",
            "Epoch 38: val_accuracy improved from 0.68750 to 0.68900, saving model to /content/drive/MyDrive/dogcat_mini/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as patch_embbeding_1_layer_call_fn, patch_embbeding_1_layer_call_and_return_conditional_losses, dropout_18_layer_call_fn, dropout_18_layer_call_and_return_conditional_losses, layer_normalization_17_layer_call_fn while saving (showing 5 of 161). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200/200 [==============================] - 107s 533ms/step - loss: 0.6015 - accuracy: 0.6674 - val_loss: 0.5844 - val_accuracy: 0.6890 - lr: 0.0010\n",
            "\n",
            "Epoch 39: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 39/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.6003 - accuracy: 0.6674\n",
            "Epoch 39: val_accuracy did not improve from 0.68900\n",
            "200/200 [==============================] - 98s 488ms/step - loss: 0.6003 - accuracy: 0.6674 - val_loss: 0.5863 - val_accuracy: 0.6825 - lr: 0.0010\n",
            "\n",
            "Epoch 40: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 40/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5985 - accuracy: 0.6780\n",
            "Epoch 40: val_accuracy improved from 0.68900 to 0.69050, saving model to /content/drive/MyDrive/dogcat_mini/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as patch_embbeding_1_layer_call_fn, patch_embbeding_1_layer_call_and_return_conditional_losses, dropout_18_layer_call_fn, dropout_18_layer_call_and_return_conditional_losses, layer_normalization_17_layer_call_fn while saving (showing 5 of 161). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200/200 [==============================] - 109s 542ms/step - loss: 0.5985 - accuracy: 0.6780 - val_loss: 0.5780 - val_accuracy: 0.6905 - lr: 0.0010\n",
            "\n",
            "Epoch 41: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 41/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5975 - accuracy: 0.6728\n",
            "Epoch 41: val_accuracy did not improve from 0.69050\n",
            "200/200 [==============================] - 98s 490ms/step - loss: 0.5975 - accuracy: 0.6728 - val_loss: 0.6049 - val_accuracy: 0.6615 - lr: 0.0010\n",
            "\n",
            "Epoch 42: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 42/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5949 - accuracy: 0.6734\n",
            "Epoch 42: val_accuracy improved from 0.69050 to 0.69950, saving model to /content/drive/MyDrive/dogcat_mini/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as patch_embbeding_1_layer_call_fn, patch_embbeding_1_layer_call_and_return_conditional_losses, dropout_18_layer_call_fn, dropout_18_layer_call_and_return_conditional_losses, layer_normalization_17_layer_call_fn while saving (showing 5 of 161). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200/200 [==============================] - 109s 542ms/step - loss: 0.5949 - accuracy: 0.6734 - val_loss: 0.5755 - val_accuracy: 0.6995 - lr: 0.0010\n",
            "\n",
            "Epoch 43: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 43/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5934 - accuracy: 0.6800\n",
            "Epoch 43: val_accuracy improved from 0.69950 to 0.70250, saving model to /content/drive/MyDrive/dogcat_mini/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as patch_embbeding_1_layer_call_fn, patch_embbeding_1_layer_call_and_return_conditional_losses, dropout_18_layer_call_fn, dropout_18_layer_call_and_return_conditional_losses, layer_normalization_17_layer_call_fn while saving (showing 5 of 161). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200/200 [==============================] - 111s 551ms/step - loss: 0.5934 - accuracy: 0.6800 - val_loss: 0.5733 - val_accuracy: 0.7025 - lr: 0.0010\n",
            "\n",
            "Epoch 44: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 44/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5941 - accuracy: 0.6764\n",
            "Epoch 44: val_accuracy did not improve from 0.70250\n",
            "200/200 [==============================] - 99s 495ms/step - loss: 0.5941 - accuracy: 0.6764 - val_loss: 0.6298 - val_accuracy: 0.6530 - lr: 0.0010\n",
            "\n",
            "Epoch 45: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 45/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5863 - accuracy: 0.6886\n",
            "Epoch 45: val_accuracy did not improve from 0.70250\n",
            "200/200 [==============================] - 94s 468ms/step - loss: 0.5863 - accuracy: 0.6886 - val_loss: 0.6072 - val_accuracy: 0.6575 - lr: 0.0010\n",
            "\n",
            "Epoch 46: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 46/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5866 - accuracy: 0.6834\n",
            "Epoch 46: val_accuracy improved from 0.70250 to 0.70550, saving model to /content/drive/MyDrive/dogcat_mini/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as patch_embbeding_1_layer_call_fn, patch_embbeding_1_layer_call_and_return_conditional_losses, dropout_18_layer_call_fn, dropout_18_layer_call_and_return_conditional_losses, layer_normalization_17_layer_call_fn while saving (showing 5 of 161). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200/200 [==============================] - 99s 495ms/step - loss: 0.5866 - accuracy: 0.6834 - val_loss: 0.5667 - val_accuracy: 0.7055 - lr: 0.0010\n",
            "\n",
            "Epoch 47: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 47/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5841 - accuracy: 0.6918\n",
            "Epoch 47: val_accuracy improved from 0.70550 to 0.71600, saving model to /content/drive/MyDrive/dogcat_mini/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as patch_embbeding_1_layer_call_fn, patch_embbeding_1_layer_call_and_return_conditional_losses, dropout_18_layer_call_fn, dropout_18_layer_call_and_return_conditional_losses, layer_normalization_17_layer_call_fn while saving (showing 5 of 161). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200/200 [==============================] - 100s 497ms/step - loss: 0.5841 - accuracy: 0.6918 - val_loss: 0.5553 - val_accuracy: 0.7160 - lr: 0.0010\n",
            "\n",
            "Epoch 48: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 48/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5784 - accuracy: 0.6942\n",
            "Epoch 48: val_accuracy did not improve from 0.71600\n",
            "200/200 [==============================] - 91s 455ms/step - loss: 0.5784 - accuracy: 0.6942 - val_loss: 0.5540 - val_accuracy: 0.7145 - lr: 0.0010\n",
            "\n",
            "Epoch 49: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 49/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5784 - accuracy: 0.6998\n",
            "Epoch 49: val_accuracy improved from 0.71600 to 0.72850, saving model to /content/drive/MyDrive/dogcat_mini/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as patch_embbeding_1_layer_call_fn, patch_embbeding_1_layer_call_and_return_conditional_losses, dropout_18_layer_call_fn, dropout_18_layer_call_and_return_conditional_losses, layer_normalization_17_layer_call_fn while saving (showing 5 of 161). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200/200 [==============================] - 101s 504ms/step - loss: 0.5784 - accuracy: 0.6998 - val_loss: 0.5511 - val_accuracy: 0.7285 - lr: 0.0010\n",
            "\n",
            "Epoch 50: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 50/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5714 - accuracy: 0.7018\n",
            "Epoch 50: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 91s 453ms/step - loss: 0.5714 - accuracy: 0.7018 - val_loss: 0.5472 - val_accuracy: 0.7205 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 51: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 51/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5605 - accuracy: 0.7154\n",
            "Epoch 51: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 92s 457ms/step - loss: 0.5605 - accuracy: 0.7154 - val_loss: 0.5493 - val_accuracy: 0.7175 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 52: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 52/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5651 - accuracy: 0.7018\n",
            "Epoch 52: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 90s 450ms/step - loss: 0.5651 - accuracy: 0.7018 - val_loss: 0.5467 - val_accuracy: 0.7210 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 53: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 53/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5593 - accuracy: 0.7100\n",
            "Epoch 53: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 92s 457ms/step - loss: 0.5593 - accuracy: 0.7100 - val_loss: 0.5415 - val_accuracy: 0.7245 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 54: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 54/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5694 - accuracy: 0.7088\n",
            "Epoch 54: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 92s 457ms/step - loss: 0.5694 - accuracy: 0.7088 - val_loss: 0.5436 - val_accuracy: 0.7195 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 55: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 55/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5649 - accuracy: 0.7052\n",
            "Epoch 55: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 91s 454ms/step - loss: 0.5649 - accuracy: 0.7052 - val_loss: 0.5435 - val_accuracy: 0.7210 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 56: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 56/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5634 - accuracy: 0.7070\n",
            "Epoch 56: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 93s 465ms/step - loss: 0.5634 - accuracy: 0.7070 - val_loss: 0.5422 - val_accuracy: 0.7270 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 57: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 57/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5568 - accuracy: 0.7148\n",
            "Epoch 57: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 92s 460ms/step - loss: 0.5568 - accuracy: 0.7148 - val_loss: 0.5430 - val_accuracy: 0.7235 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 58: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 58/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5597 - accuracy: 0.7102\n",
            "Epoch 58: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 91s 455ms/step - loss: 0.5597 - accuracy: 0.7102 - val_loss: 0.5407 - val_accuracy: 0.7225 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 59: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 59/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5567 - accuracy: 0.7172\n",
            "Epoch 59: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 91s 456ms/step - loss: 0.5567 - accuracy: 0.7172 - val_loss: 0.5470 - val_accuracy: 0.7165 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 60: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 60/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5595 - accuracy: 0.7090\n",
            "Epoch 60: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 90s 450ms/step - loss: 0.5595 - accuracy: 0.7090 - val_loss: 0.5432 - val_accuracy: 0.7200 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 61: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 61/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5644 - accuracy: 0.7084\n",
            "Epoch 61: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 91s 455ms/step - loss: 0.5644 - accuracy: 0.7084 - val_loss: 0.5389 - val_accuracy: 0.7250 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 62: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 62/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5566 - accuracy: 0.7168\n",
            "Epoch 62: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 92s 459ms/step - loss: 0.5566 - accuracy: 0.7168 - val_loss: 0.5421 - val_accuracy: 0.7165 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 63: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 63/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5607 - accuracy: 0.7140\n",
            "Epoch 63: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 94s 467ms/step - loss: 0.5607 - accuracy: 0.7140 - val_loss: 0.5465 - val_accuracy: 0.7140 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 64: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 64/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5625 - accuracy: 0.7032\n",
            "Epoch 64: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 97s 485ms/step - loss: 0.5625 - accuracy: 0.7032 - val_loss: 0.5431 - val_accuracy: 0.7185 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 65: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 65/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5582 - accuracy: 0.7080\n",
            "Epoch 65: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 99s 496ms/step - loss: 0.5582 - accuracy: 0.7080 - val_loss: 0.5407 - val_accuracy: 0.7235 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 66: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 66/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5601 - accuracy: 0.7074\n",
            "Epoch 66: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 99s 492ms/step - loss: 0.5601 - accuracy: 0.7074 - val_loss: 0.5426 - val_accuracy: 0.7220 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 67: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 67/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5608 - accuracy: 0.7100\n",
            "Epoch 67: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 96s 481ms/step - loss: 0.5608 - accuracy: 0.7100 - val_loss: 0.5402 - val_accuracy: 0.7220 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 68: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 68/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5610 - accuracy: 0.7062\n",
            "Epoch 68: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 96s 479ms/step - loss: 0.5610 - accuracy: 0.7062 - val_loss: 0.5383 - val_accuracy: 0.7205 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 69: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 69/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5608 - accuracy: 0.7134\n",
            "Epoch 69: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 96s 477ms/step - loss: 0.5608 - accuracy: 0.7134 - val_loss: 0.5396 - val_accuracy: 0.7190 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 70: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 70/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5542 - accuracy: 0.7138\n",
            "Epoch 70: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 94s 469ms/step - loss: 0.5542 - accuracy: 0.7138 - val_loss: 0.5398 - val_accuracy: 0.7205 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 71: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 71/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5659 - accuracy: 0.7008\n",
            "Epoch 71: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 92s 461ms/step - loss: 0.5659 - accuracy: 0.7008 - val_loss: 0.5393 - val_accuracy: 0.7190 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 72: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 72/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5590 - accuracy: 0.7086\n",
            "Epoch 72: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 92s 460ms/step - loss: 0.5590 - accuracy: 0.7086 - val_loss: 0.5399 - val_accuracy: 0.7200 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 73: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 73/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5584 - accuracy: 0.7162\n",
            "Epoch 73: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 92s 460ms/step - loss: 0.5584 - accuracy: 0.7162 - val_loss: 0.5384 - val_accuracy: 0.7265 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 74: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 74/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5599 - accuracy: 0.7106\n",
            "Epoch 74: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 92s 459ms/step - loss: 0.5599 - accuracy: 0.7106 - val_loss: 0.5413 - val_accuracy: 0.7235 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 75: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 75/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5565 - accuracy: 0.7104\n",
            "Epoch 75: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 92s 459ms/step - loss: 0.5565 - accuracy: 0.7104 - val_loss: 0.5383 - val_accuracy: 0.7250 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 76: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 76/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5616 - accuracy: 0.7120\n",
            "Epoch 76: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 92s 456ms/step - loss: 0.5616 - accuracy: 0.7120 - val_loss: 0.5358 - val_accuracy: 0.7230 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 77: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 77/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5489 - accuracy: 0.7194\n",
            "Epoch 77: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 92s 460ms/step - loss: 0.5489 - accuracy: 0.7194 - val_loss: 0.5380 - val_accuracy: 0.7260 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 78: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 78/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5506 - accuracy: 0.7200\n",
            "Epoch 78: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 91s 454ms/step - loss: 0.5506 - accuracy: 0.7200 - val_loss: 0.5379 - val_accuracy: 0.7280 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 79: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 79/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5625 - accuracy: 0.7062\n",
            "Epoch 79: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 91s 453ms/step - loss: 0.5625 - accuracy: 0.7062 - val_loss: 0.5364 - val_accuracy: 0.7270 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 80: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 80/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5563 - accuracy: 0.7086\n",
            "Epoch 80: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 91s 454ms/step - loss: 0.5563 - accuracy: 0.7086 - val_loss: 0.5408 - val_accuracy: 0.7220 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 81: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 81/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5621 - accuracy: 0.7050\n",
            "Epoch 81: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 91s 452ms/step - loss: 0.5621 - accuracy: 0.7050 - val_loss: 0.5398 - val_accuracy: 0.7195 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 82: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 82/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5582 - accuracy: 0.7080\n",
            "Epoch 82: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 90s 450ms/step - loss: 0.5582 - accuracy: 0.7080 - val_loss: 0.5361 - val_accuracy: 0.7270 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 83: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 83/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5606 - accuracy: 0.7140\n",
            "Epoch 83: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 90s 451ms/step - loss: 0.5606 - accuracy: 0.7140 - val_loss: 0.5362 - val_accuracy: 0.7210 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 84: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 84/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5577 - accuracy: 0.7080\n",
            "Epoch 84: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 90s 451ms/step - loss: 0.5577 - accuracy: 0.7080 - val_loss: 0.5377 - val_accuracy: 0.7175 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 85: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 85/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5509 - accuracy: 0.7158\n",
            "Epoch 85: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 90s 451ms/step - loss: 0.5509 - accuracy: 0.7158 - val_loss: 0.5394 - val_accuracy: 0.7205 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 86: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 86/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5593 - accuracy: 0.7084\n",
            "Epoch 86: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 90s 448ms/step - loss: 0.5593 - accuracy: 0.7084 - val_loss: 0.5403 - val_accuracy: 0.7240 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 87: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 87/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5549 - accuracy: 0.7162\n",
            "Epoch 87: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 90s 448ms/step - loss: 0.5549 - accuracy: 0.7162 - val_loss: 0.5369 - val_accuracy: 0.7190 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 88: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 88/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5543 - accuracy: 0.7192\n",
            "Epoch 88: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 90s 446ms/step - loss: 0.5543 - accuracy: 0.7192 - val_loss: 0.5341 - val_accuracy: 0.7270 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 89: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 89/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5624 - accuracy: 0.7096\n",
            "Epoch 89: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 90s 450ms/step - loss: 0.5624 - accuracy: 0.7096 - val_loss: 0.5377 - val_accuracy: 0.7185 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 90: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 90/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5539 - accuracy: 0.7162\n",
            "Epoch 90: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 90s 447ms/step - loss: 0.5539 - accuracy: 0.7162 - val_loss: 0.5419 - val_accuracy: 0.7170 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 91: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 91/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5580 - accuracy: 0.7110\n",
            "Epoch 91: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 90s 446ms/step - loss: 0.5580 - accuracy: 0.7110 - val_loss: 0.5339 - val_accuracy: 0.7255 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 92: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 92/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5536 - accuracy: 0.7112\n",
            "Epoch 92: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 90s 446ms/step - loss: 0.5536 - accuracy: 0.7112 - val_loss: 0.5382 - val_accuracy: 0.7215 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 93: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 93/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5514 - accuracy: 0.7150\n",
            "Epoch 93: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 89s 444ms/step - loss: 0.5514 - accuracy: 0.7150 - val_loss: 0.5327 - val_accuracy: 0.7265 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 94: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 94/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5586 - accuracy: 0.7072\n",
            "Epoch 94: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 89s 445ms/step - loss: 0.5586 - accuracy: 0.7072 - val_loss: 0.5344 - val_accuracy: 0.7240 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 95: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 95/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5548 - accuracy: 0.7108\n",
            "Epoch 95: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 89s 445ms/step - loss: 0.5548 - accuracy: 0.7108 - val_loss: 0.5359 - val_accuracy: 0.7260 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 96: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 96/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5526 - accuracy: 0.7196\n",
            "Epoch 96: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 90s 446ms/step - loss: 0.5526 - accuracy: 0.7196 - val_loss: 0.5364 - val_accuracy: 0.7250 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 97: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 97/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5533 - accuracy: 0.7150\n",
            "Epoch 97: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 89s 444ms/step - loss: 0.5533 - accuracy: 0.7150 - val_loss: 0.5356 - val_accuracy: 0.7220 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 98: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 98/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5437 - accuracy: 0.7244\n",
            "Epoch 98: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 89s 445ms/step - loss: 0.5437 - accuracy: 0.7244 - val_loss: 0.5338 - val_accuracy: 0.7275 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 99: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 99/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5546 - accuracy: 0.7160\n",
            "Epoch 99: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 90s 446ms/step - loss: 0.5546 - accuracy: 0.7160 - val_loss: 0.5329 - val_accuracy: 0.7270 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 100: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
            "Epoch 100/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5501 - accuracy: 0.7154\n",
            "Epoch 100: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 89s 445ms/step - loss: 0.5501 - accuracy: 0.7154 - val_loss: 0.5326 - val_accuracy: 0.7250 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 101: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
            "Epoch 101/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5509 - accuracy: 0.7206\n",
            "Epoch 101: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 89s 446ms/step - loss: 0.5509 - accuracy: 0.7206 - val_loss: 0.5327 - val_accuracy: 0.7255 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 102: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
            "Epoch 102/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5467 - accuracy: 0.7190\n",
            "Epoch 102: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 100s 497ms/step - loss: 0.5467 - accuracy: 0.7190 - val_loss: 0.5331 - val_accuracy: 0.7240 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 103: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
            "Epoch 103/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5509 - accuracy: 0.7196\n",
            "Epoch 103: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 89s 445ms/step - loss: 0.5509 - accuracy: 0.7196 - val_loss: 0.5331 - val_accuracy: 0.7255 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 104: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
            "Epoch 104/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5519 - accuracy: 0.7172\n",
            "Epoch 104: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 91s 456ms/step - loss: 0.5519 - accuracy: 0.7172 - val_loss: 0.5328 - val_accuracy: 0.7240 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 105: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
            "Epoch 105/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5488 - accuracy: 0.7114\n",
            "Epoch 105: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 89s 445ms/step - loss: 0.5488 - accuracy: 0.7114 - val_loss: 0.5329 - val_accuracy: 0.7255 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 106: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
            "Epoch 106/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5525 - accuracy: 0.7136\n",
            "Epoch 106: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 89s 444ms/step - loss: 0.5525 - accuracy: 0.7136 - val_loss: 0.5332 - val_accuracy: 0.7245 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 107: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
            "Epoch 107/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5461 - accuracy: 0.7220\n",
            "Epoch 107: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 89s 446ms/step - loss: 0.5461 - accuracy: 0.7220 - val_loss: 0.5333 - val_accuracy: 0.7240 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 108: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
            "Epoch 108/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5520 - accuracy: 0.7238\n",
            "Epoch 108: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 90s 448ms/step - loss: 0.5520 - accuracy: 0.7238 - val_loss: 0.5331 - val_accuracy: 0.7230 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 109: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
            "Epoch 109/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5499 - accuracy: 0.7152\n",
            "Epoch 109: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 89s 446ms/step - loss: 0.5499 - accuracy: 0.7152 - val_loss: 0.5328 - val_accuracy: 0.7240 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 110: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
            "Epoch 110/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5561 - accuracy: 0.7090\n",
            "Epoch 110: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 89s 446ms/step - loss: 0.5561 - accuracy: 0.7090 - val_loss: 0.5330 - val_accuracy: 0.7265 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 111: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
            "Epoch 111/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5435 - accuracy: 0.7330\n",
            "Epoch 111: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 89s 442ms/step - loss: 0.5435 - accuracy: 0.7330 - val_loss: 0.5329 - val_accuracy: 0.7255 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 112: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
            "Epoch 112/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5540 - accuracy: 0.7152\n",
            "Epoch 112: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 89s 442ms/step - loss: 0.5540 - accuracy: 0.7152 - val_loss: 0.5329 - val_accuracy: 0.7235 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 113: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
            "Epoch 113/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5549 - accuracy: 0.7190\n",
            "Epoch 113: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 89s 442ms/step - loss: 0.5549 - accuracy: 0.7190 - val_loss: 0.5323 - val_accuracy: 0.7245 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 114: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
            "Epoch 114/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5501 - accuracy: 0.7162\n",
            "Epoch 114: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 88s 438ms/step - loss: 0.5501 - accuracy: 0.7162 - val_loss: 0.5324 - val_accuracy: 0.7245 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 115: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
            "Epoch 115/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5476 - accuracy: 0.7188\n",
            "Epoch 115: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 89s 442ms/step - loss: 0.5476 - accuracy: 0.7188 - val_loss: 0.5318 - val_accuracy: 0.7255 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 116: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
            "Epoch 116/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5460 - accuracy: 0.7240\n",
            "Epoch 116: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 89s 443ms/step - loss: 0.5460 - accuracy: 0.7240 - val_loss: 0.5316 - val_accuracy: 0.7260 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 117: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
            "Epoch 117/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5403 - accuracy: 0.7244\n",
            "Epoch 117: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 88s 441ms/step - loss: 0.5403 - accuracy: 0.7244 - val_loss: 0.5315 - val_accuracy: 0.7255 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 118: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
            "Epoch 118/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5392 - accuracy: 0.7230\n",
            "Epoch 118: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 89s 443ms/step - loss: 0.5392 - accuracy: 0.7230 - val_loss: 0.5316 - val_accuracy: 0.7275 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 119: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
            "Epoch 119/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5465 - accuracy: 0.7234\n",
            "Epoch 119: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 88s 439ms/step - loss: 0.5465 - accuracy: 0.7234 - val_loss: 0.5316 - val_accuracy: 0.7255 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 120: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
            "Epoch 120/120\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5515 - accuracy: 0.7134\n",
            "Epoch 120: val_accuracy did not improve from 0.72850\n",
            "200/200 [==============================] - 88s 438ms/step - loss: 0.5515 - accuracy: 0.7134 - val_loss: 0.5317 - val_accuracy: 0.7260 - lr: 1.0000e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bkiUzFewyinJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "for f in os.listdir(\"/content/drive/MyDrive/dogcat_mini/val/Dog\"):\n",
        "  Image.open(\"/content/drive/MyDrive/dogcat_mini/val/Dog/\"+f)"
      ],
      "metadata": {
        "id": "fyAWR6yruHYJ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model = load_model(\"/content/drive/MyDrive/dogcat_mini/\")"
      ],
      "metadata": {
        "id": "Z0ymFDAY_WEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "re6EN1RLCCJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "\n",
        "model2 = tf.keras.Sequential([\n",
        "                             hub.KerasLayer(\"https://tfhub.dev/sayakpaul/vit_b16_fe/1\", trainable=False),\n",
        "                             Dense(16, activation='tanh'),\n",
        "                             Dropout(0.5),\n",
        "                             Dense(1, activation='sigmoid')\n",
        "                             ])"
      ],
      "metadata": {
        "id": "HrxGqKi1CDjS"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=25\n",
        "epochs = 10\n",
        "initial_lrate = 0.001\n",
        "\n",
        "# Checkpoint -- ベストのモデルのみ保存\n",
        "modelCheckpoint = ModelCheckpoint(filepath = \"/content/drive/MyDrive/dogcat_mini/model2/\",\n",
        "                                  monitor='val_accuracy',\n",
        "                                  verbose=1,\n",
        "                                  save_best_only=True,\n",
        "                                  save_weights_only=False, # 重みのみ保存\n",
        "                                  mode='max', # val_accuracyの場合\n",
        "                                  period=1)\n",
        "\n",
        "def decay(epoch, steps=50):\n",
        "    initial_lrate = 0.001\n",
        "    drop = 0.1\n",
        "    epochs_drop = 50\n",
        "    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
        "    if lrate <= 1e-6:\n",
        "      lrate=1e-6\n",
        "    return lrate\n",
        "\n",
        "sgd = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.99, weight_decay=0.1)\n",
        "\n",
        "lr_sc = LearningRateScheduler(decay, verbose=1)\n",
        "\n",
        "model2.compile(loss=['binary_crossentropy'], optimizer=sgd,  metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmNKtMA8CDlT",
        "outputId": "5656704b-9000-47f7-bba5-557b26f3483d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history=model2.fit(train_generator,\n",
        "                  #batch_size=batch_size,\n",
        "                  epochs=epochs,\n",
        "                  #steps_per_epoch=int(len(x_train)//batch_size),\n",
        "                  validation_data=validation_generator,\n",
        "                  #validation_steps=int(len(x_test)//batch_size),\n",
        "                  callbacks = [modelCheckpoint, lr_sc]\n",
        "                  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vz4lyq9Gm0cx",
        "outputId": "08c5c571-29f9-4329-8d49-b65e0c8e70d2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1/10\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.1038 - accuracy: 0.9640\n",
            "Epoch 1: val_accuracy improved from -inf to 0.99550, saving model to /content/drive/MyDrive/dogcat_mini/model2/\n",
            "200/200 [==============================] - 128s 601ms/step - loss: 0.1038 - accuracy: 0.9640 - val_loss: 0.0208 - val_accuracy: 0.9955 - lr: 0.0010\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 2/10\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0396 - accuracy: 0.9892\n",
            "Epoch 2: val_accuracy improved from 0.99550 to 0.99600, saving model to /content/drive/MyDrive/dogcat_mini/model2/\n",
            "200/200 [==============================] - 115s 576ms/step - loss: 0.0396 - accuracy: 0.9892 - val_loss: 0.0184 - val_accuracy: 0.9960 - lr: 0.0010\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 3/10\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0333 - accuracy: 0.9898\n",
            "Epoch 3: val_accuracy did not improve from 0.99600\n",
            "200/200 [==============================] - 103s 512ms/step - loss: 0.0333 - accuracy: 0.9898 - val_loss: 0.0187 - val_accuracy: 0.9955 - lr: 0.0010\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 4/10\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0292 - accuracy: 0.9912\n",
            "Epoch 4: val_accuracy did not improve from 0.99600\n",
            "200/200 [==============================] - 103s 513ms/step - loss: 0.0292 - accuracy: 0.9912 - val_loss: 0.0178 - val_accuracy: 0.9960 - lr: 0.0010\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 5/10\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0278 - accuracy: 0.9932\n",
            "Epoch 5: val_accuracy did not improve from 0.99600\n",
            "200/200 [==============================] - 103s 513ms/step - loss: 0.0278 - accuracy: 0.9932 - val_loss: 0.0169 - val_accuracy: 0.9955 - lr: 0.0010\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 6/10\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0241 - accuracy: 0.9924\n",
            "Epoch 6: val_accuracy did not improve from 0.99600\n",
            "200/200 [==============================] - 103s 514ms/step - loss: 0.0241 - accuracy: 0.9924 - val_loss: 0.0173 - val_accuracy: 0.9960 - lr: 0.0010\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 7/10\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0245 - accuracy: 0.9924\n",
            "Epoch 7: val_accuracy did not improve from 0.99600\n",
            "200/200 [==============================] - 103s 513ms/step - loss: 0.0245 - accuracy: 0.9924 - val_loss: 0.0163 - val_accuracy: 0.9960 - lr: 0.0010\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 8/10\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0292 - accuracy: 0.9906\n",
            "Epoch 8: val_accuracy did not improve from 0.99600\n",
            "200/200 [==============================] - 103s 515ms/step - loss: 0.0292 - accuracy: 0.9906 - val_loss: 0.0177 - val_accuracy: 0.9945 - lr: 0.0010\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 9/10\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0241 - accuracy: 0.9934\n",
            "Epoch 9: val_accuracy did not improve from 0.99600\n",
            "200/200 [==============================] - 103s 512ms/step - loss: 0.0241 - accuracy: 0.9934 - val_loss: 0.0167 - val_accuracy: 0.9950 - lr: 0.0010\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 10/10\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0213 - accuracy: 0.9920\n",
            "Epoch 10: val_accuracy did not improve from 0.99600\n",
            "200/200 [==============================] - 105s 524ms/step - loss: 0.0213 - accuracy: 0.9920 - val_loss: 0.0165 - val_accuracy: 0.9955 - lr: 0.0010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AUnmBVExoivq"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install vit-keras\n",
        "!pip install tensorflow_addons\n",
        "from vit_keras import vit\n",
        "\n",
        "image_size = 224\n",
        "base_model = vit.vit_b16(\n",
        "    image_size=image_size,\n",
        "    activation='sigmoid',\n",
        "    pretrained=True,\n",
        "    include_top=True,\n",
        "    pretrained_top=False,\n",
        "    classes=1\n",
        ")\n",
        "\n",
        "# 学習させない\n",
        "for layer in base_model.layers[:6]:\n",
        "    layer.trainable = False\n",
        "\n",
        "#model3 = tf.keras.Sequential([\n",
        "#                             base_model,\n",
        "#                             Dense(16, activation='tanh'),\n",
        "#                             Dropout(0.5),\n",
        "#                             Dense(1, activation='sigmoid')\n",
        "#                             ])\n",
        "model3 = base_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWDjxn7csTlb",
        "outputId": "ef5f510d-a200-425a-c3d8-2dee15fbf025"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: vit-keras in /usr/local/lib/python3.9/dist-packages (0.1.0)\n",
            "Requirement already satisfied: validators in /usr/local/lib/python3.9/dist-packages (from vit-keras) (0.20.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from vit-keras) (1.10.1)\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.9/dist-packages (from scipy->vit-keras) (1.22.4)\n",
            "Requirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.9/dist-packages (from validators->vit-keras) (4.4.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow_addons in /usr/local/lib/python3.9/dist-packages (0.19.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.9/dist-packages (from tensorflow_addons) (3.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorflow_addons) (23.0)\n",
            "Requirement already satisfied: importlib-metadata>=3.6 in /usr/local/lib/python3.9/dist-packages (from typeguard>=2.7->tensorflow_addons) (6.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.9/dist-packages (from typeguard>=2.7->tensorflow_addons) (4.5.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=3.6->typeguard>=2.7->tensorflow_addons) (3.15.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/vit_keras/utils.py:81: UserWarning: Resizing position embeddings from 24, 24 to 14, 14\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = test_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/dogcat_mini/train',\n",
        "        target_size=(img_height, img_width),\n",
        "        color_mode = 'rgb', #グレー:'grayscale'\n",
        "        batch_size=batch_size,\n",
        "        classes = classes, \n",
        "        class_mode='binary',#2つ'binary' 3つ以上:'categorical'\n",
        "        save_format='jpeg'\n",
        ")\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/dogcat_mini/val',\n",
        "        target_size=(img_height, img_width),\n",
        "        batch_size=batch_size,\n",
        "        classes = classes, \n",
        "        class_mode='binary',\n",
        "        save_format='jpeg')\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/dogcat_mini/test',\n",
        "        target_size=(img_height, img_width),\n",
        "        batch_size=batch_size,\n",
        "        classes = classes, \n",
        "        class_mode='binary',\n",
        "        save_format='jpeg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KwPQvSizQtt",
        "outputId": "d60283ae-5cb3-49a3-b98d-d727eab4d09e"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5000 images belonging to 2 classes.\n",
            "Found 2000 images belonging to 2 classes.\n",
            "Found 200 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=25\n",
        "epochs = 10\n",
        "initial_lrate = 0.001\n",
        "\n",
        "# Checkpoint -- ベストのモデルのみ保存\n",
        "modelCheckpoint = ModelCheckpoint(filepath = \"/content/drive/MyDrive/dogcat_mini/model3/\",\n",
        "                                  monitor='val_accuracy',\n",
        "                                  verbose=1,\n",
        "                                  save_best_only=True,\n",
        "                                  save_weights_only=False, # 重みのみ保存\n",
        "                                  mode='max', # val_accuracyの場合\n",
        "                                  period=1)\n",
        "\n",
        "def decay(epoch, steps=50):\n",
        "    initial_lrate = 0.001\n",
        "    drop = 0.1\n",
        "    epochs_drop = 50\n",
        "    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
        "    if lrate <= 1e-6:\n",
        "      lrate=1e-6\n",
        "    return lrate\n",
        "\n",
        "sgd = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.99, weight_decay=0.1)\n",
        "\n",
        "lr_sc = LearningRateScheduler(decay, verbose=1)\n",
        "\n",
        "model3.compile(loss=['binary_crossentropy'], optimizer=sgd,  metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgwTmUiuvBKd",
        "outputId": "36fc5c70-cc5b-4ba7-d266-fd4737f51e45"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history3=model3.fit(train_generator,\n",
        "                  epochs=epochs,\n",
        "                  validation_data=validation_generator,\n",
        "                  callbacks = [modelCheckpoint, lr_sc]\n",
        "                  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxUdWE0JsTFZ",
        "outputId": "acb27c97-8bb5-4be5-9487-3406af20ef53"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1/10\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.3546 - accuracy: 0.8490\n",
            "Epoch 1: val_accuracy improved from -inf to 0.91100, saving model to /content/drive/MyDrive/dogcat_mini/model3/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, MultiHeadDotProductAttention_1_layer_call_fn, MultiHeadDotProductAttention_1_layer_call_and_return_conditional_losses, LayerNorm_0_layer_call_fn, LayerNorm_0_layer_call_and_return_conditional_losses while saving (showing 5 of 193). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200/200 [==============================] - 307s 1s/step - loss: 0.3546 - accuracy: 0.8490 - val_loss: 0.2156 - val_accuracy: 0.9110 - lr: 0.0010\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 2/10\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.1666 - accuracy: 0.9330\n",
            "Epoch 2: val_accuracy did not improve from 0.91100\n",
            "200/200 [==============================] - 221s 1s/step - loss: 0.1666 - accuracy: 0.9330 - val_loss: 0.2324 - val_accuracy: 0.9085 - lr: 0.0010\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 3/10\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.1609 - accuracy: 0.9406\n",
            "Epoch 3: val_accuracy did not improve from 0.91100\n",
            "200/200 [==============================] - 221s 1s/step - loss: 0.1609 - accuracy: 0.9406 - val_loss: 0.2505 - val_accuracy: 0.8980 - lr: 0.0010\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 4/10\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.1476 - accuracy: 0.9448\n",
            "Epoch 4: val_accuracy did not improve from 0.91100\n",
            "200/200 [==============================] - 221s 1s/step - loss: 0.1476 - accuracy: 0.9448 - val_loss: 0.2968 - val_accuracy: 0.9090 - lr: 0.0010\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 5/10\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.1343 - accuracy: 0.9494\n",
            "Epoch 5: val_accuracy did not improve from 0.91100\n",
            "200/200 [==============================] - 221s 1s/step - loss: 0.1343 - accuracy: 0.9494 - val_loss: 0.4172 - val_accuracy: 0.8985 - lr: 0.0010\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 6/10\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.1168 - accuracy: 0.9574\n",
            "Epoch 6: val_accuracy improved from 0.91100 to 0.92050, saving model to /content/drive/MyDrive/dogcat_mini/model3/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, MultiHeadDotProductAttention_1_layer_call_fn, MultiHeadDotProductAttention_1_layer_call_and_return_conditional_losses, LayerNorm_0_layer_call_fn, LayerNorm_0_layer_call_and_return_conditional_losses while saving (showing 5 of 193). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200/200 [==============================] - 260s 1s/step - loss: 0.1168 - accuracy: 0.9574 - val_loss: 0.2282 - val_accuracy: 0.9205 - lr: 0.0010\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 7/10\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.1066 - accuracy: 0.9654\n",
            "Epoch 7: val_accuracy did not improve from 0.92050\n",
            "200/200 [==============================] - 221s 1s/step - loss: 0.1066 - accuracy: 0.9654 - val_loss: 0.2201 - val_accuracy: 0.9160 - lr: 0.0010\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 8/10\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.1333 - accuracy: 0.9536\n",
            "Epoch 8: val_accuracy did not improve from 0.92050\n",
            "200/200 [==============================] - 221s 1s/step - loss: 0.1333 - accuracy: 0.9536 - val_loss: 0.3763 - val_accuracy: 0.8790 - lr: 0.0010\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 9/10\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0861 - accuracy: 0.9664\n",
            "Epoch 9: val_accuracy did not improve from 0.92050\n",
            "200/200 [==============================] - 221s 1s/step - loss: 0.0861 - accuracy: 0.9664 - val_loss: 0.2318 - val_accuracy: 0.9030 - lr: 0.0010\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 10/10\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0856 - accuracy: 0.9692\n",
            "Epoch 10: val_accuracy did not improve from 0.92050\n",
            "200/200 [==============================] - 221s 1s/step - loss: 0.0856 - accuracy: 0.9692 - val_loss: 0.2484 - val_accuracy: 0.9165 - lr: 0.0010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model3.evaluate(test_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IHBsuk-8oeA",
        "outputId": "4d516c68-d670-423b-d204-407e9141dd14"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 3s 337ms/step - loss: 0.3209 - accuracy: 0.9050\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3208948075771332, 0.9049999713897705]"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from vit_keras import vit, utils, visualize\n",
        "\n",
        "imgs = next(validation_generator)\n",
        "\n",
        "attention_map = visualize.attention_map(model=model3, image=imgs[0][6])\n",
        "\n",
        "# Plot results\n",
        "fig, (ax1, ax2) = plt.subplots(ncols=2)\n",
        "ax1.axis('off')\n",
        "ax2.axis('off')\n",
        "ax1.set_title('Original')\n",
        "ax2.set_title('Attention Map')\n",
        "_ = ax1.imshow(imgs[0][5])\n",
        "_ = ax2.imshow(attention_map)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "o0DH1z1NFnpj",
        "outputId": "58de8c8e-3746-4e65-f61c-48d302e653f4"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 3s 3s/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_map.max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSSP9yziPMJN",
        "outputId": "c3ea3b98-4041-4056-ae81-daf7c1ae1ef1"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SIaJS_xUI40-"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.layers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDe6tVOvGv5B",
        "outputId": "1b5dc9cd-e38a-4717-976e-0c45518d4de0"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<keras.engine.input_layer.InputLayer at 0x7fd0d8273f10>,\n",
              " <keras.layers.convolutional.conv2d.Conv2D at 0x7fd0d8793760>,\n",
              " <keras.layers.reshaping.reshape.Reshape at 0x7fd0d86190d0>,\n",
              " <vit_keras.layers.ClassToken at 0x7fd0d8619c10>,\n",
              " <vit_keras.layers.AddPositionEmbs at 0x7fd0d86f5af0>,\n",
              " <vit_keras.layers.TransformerBlock at 0x7fd0d87077f0>,\n",
              " <vit_keras.layers.TransformerBlock at 0x7fd0d86f1a00>,\n",
              " <vit_keras.layers.TransformerBlock at 0x7fd0765b9310>,\n",
              " <vit_keras.layers.TransformerBlock at 0x7fd076543c40>,\n",
              " <vit_keras.layers.TransformerBlock at 0x7fd076552310>,\n",
              " <vit_keras.layers.TransformerBlock at 0x7fd042ddc310>,\n",
              " <vit_keras.layers.TransformerBlock at 0x7fd0764d8550>,\n",
              " <vit_keras.layers.TransformerBlock at 0x7fd042d1f820>,\n",
              " <vit_keras.layers.TransformerBlock at 0x7fd042dc6a60>,\n",
              " <vit_keras.layers.TransformerBlock at 0x7fd042d64dc0>,\n",
              " <vit_keras.layers.TransformerBlock at 0x7fd042da8700>,\n",
              " <vit_keras.layers.TransformerBlock at 0x7fd0764ce190>,\n",
              " <keras.layers.normalization.layer_normalization.LayerNormalization at 0x7fd0d8707760>,\n",
              " <keras.layers.core.lambda_layer.Lambda at 0x7fd0765b9370>]"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optimizers\n",
        "\n",
        "import numpy as np\n",
        "import math"
      ],
      "metadata": {
        "id": "eHFEQAaPCDnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PatchEmbedding(nn.Module):\n",
        "  def __init__(self):\n",
        "    \n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    '''\n",
        "    Multi-Head Attentionレイヤ\n",
        "    \n",
        "    hidden_dim : Embeddingされた単語ベクトルの長さ\n",
        "    heads_num : マルチヘッドAttentionのヘッド数\n",
        "       ※hidden_numはheads_numで割り切れえる値とすること\n",
        "    drop_rate : 出力のDropout率\n",
        "\n",
        "    model = MultiheadAttention(\n",
        "        hidden_dim = 512,\n",
        "        head_num = 8,\n",
        "        drop_rate = 0.5\n",
        "    )\n",
        "    '''\n",
        "    def __init__(self, token_num, hidden_dim, heads_num, drop_rate=0.5):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        # 入力の線形変換\n",
        "        # 重み行列は[hidden_dim, hidden_dim]\n",
        "        self.query = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.key   = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.value = nn.Linear(hidden_dim, hidden_dim)\n",
        "        \n",
        "        # 出力の線形変換\n",
        "        self.projection = nn.Linear(hidden_dim, hidden_dim)\n",
        "        \n",
        "        # 出力のDropout\n",
        "        self.drop = nn.Dropout(drop_rate)\n",
        "        \n",
        "        self.nf = hidden_dim\n",
        "        self.nh = heads_num\n",
        "    \n",
        "    def atten(self, query, key, value, attention_mask):\n",
        "        \"\"\"\n",
        "        Attention\n",
        "        \n",
        "        query, key, value : 入力\n",
        "        attention_mask : attention weight に適用される mask\n",
        "        \"\"\"\n",
        "        # 各値を取得\n",
        "        shape = query.shape\n",
        "        batch_size = -1 if shape[0] is None else shape[0]\n",
        "        token_num = shape[2] # トークン列数\n",
        "        hidden_dim = shape[1]*shape[3] # 入力チャンネル数\n",
        "        \n",
        "        # ここで q と k の内積を取ることで、query と key の単語間の関連度のようなものを計算します。\n",
        "        # tf.matmulで最後の2成分について積を計算(それ以外は形がそろっている必要あり)\n",
        "        # transpose_bで転置\n",
        "        # [token_num, hidden_dim/head_num] @ [hidden_dim/head_num, token_num] = [token_num, token_num]\n",
        "        scores = torch.matmul(query, key.transpose(-2, -1))\n",
        "        \n",
        "        # scoreをhidden_dimの平方根割る\n",
        "        scores = scores / math.sqrt(hidden_dim)\n",
        "        \n",
        "        # Attention Maskがあればscoreに加算\n",
        "        # attention_mask: [batch_size, token_num, token_num] \n",
        "        # マスク(参照しない部分)の場所に1、使用する部分は0とする\n",
        "        # 0の部分を -無限大にする(softmax(-無限大)=0となる)\n",
        "        # 1. PADを無視\n",
        "        # 2. DecoderのSelf-Attentionで未来の情報を参照できないようにする\n",
        "        if attention_mask is not None:\n",
        "            scores = scores.masked_fill(attention_mask == 1, -1e9)\n",
        "\n",
        "        # softmax を取ることで正規化します\n",
        "        # input(query) の各単語に対して memory(key) の各単語のどこから情報を引いてくるかの重み\n",
        "        atten_weight = F.softmax(scores, dim = -1)\n",
        "        #atten_weight = scores / torch.sum(scores, dim=-1, keepdim=True)\n",
        "        \n",
        "        # 重みに従って value から情報を引いてきます\n",
        "        # [token_num, token_num] @ [token_num, hidden_dim/head_num] = [token_num, hidden_dim/head_num]\n",
        "        # input(query) の単語ごとに memory(value)の各単語 に attention_weight を掛け合わせて足し合わせた ベクトル(分散表現の重み付き和)を計算\n",
        "        context = torch.matmul(atten_weight, value)\n",
        "        \n",
        "        # 各ヘッドの結合(reshape)\n",
        "        # 入力と同じ形に変換する\n",
        "        context = context.transpose(1, 2).contiguous()\n",
        "        context = context.view(batch_size, token_num, hidden_dim)\n",
        "        \n",
        "        # 線形変換\n",
        "        context = self.projection(context)\n",
        "        \n",
        "        return self.drop(context), atten_weight\n",
        "\n",
        "    def _split(self, x):\n",
        "        \"\"\"\n",
        "        query, key, valueを分割する\n",
        "        \n",
        "        入力 shape: [batch_size, length, hidden_dim] の時\n",
        "        出力 shape: [batch_size, head_num, length, hidden_dim//head_num]\n",
        "        \"\"\"\n",
        "        # 各値を取得\n",
        "        hidden_dim = self.nf\n",
        "        heads_num = self.nh\n",
        "        shape = x.shape\n",
        "        batch_size = -1 if shape[0] is None else shape[0]\n",
        "        token_num = shape[1] # トークン列数\n",
        "        \n",
        "        # [batch_size, token_num, hidden_dim] -> [batch_size, token_num, head_num, hidden_dim/head_num]\n",
        "        # splitだが実際は次元を拡張する処理\n",
        "        x = x.view(batch_size, token_num, heads_num, int(hidden_dim/heads_num))\n",
        "        \n",
        "        # [batch_size, token_num, head_num, hidden_dim/head_num] -> [batch_size, head_num, token_num, hidden_dim/head_num]\n",
        "        x = x.transpose(1, 2)\n",
        "        return x\n",
        "    \n",
        "    def forward(self, x, memory=None, attention_mask=None, return_attention_scores=False):\n",
        "        \"\"\"\n",
        "        モデルの実行\n",
        "        \n",
        "        input : 入力(query) [batch_size, token_num, hidden_dim]\n",
        "        memory : 入力(key, value) [batch_size, token_num, hidden_dim]\n",
        "        attention_mask : attention weight に適用される mask\n",
        "            [batch_size, 1, q_length, k_length] \n",
        "            pad 等無視する部分が 1 となるようなもの(Decoderで使用)\n",
        "        \"\"\"\n",
        "        # memoryが入力されない場合、memory=input(Self Attention)とする\n",
        "        if memory is None:\n",
        "            memory = x\n",
        "        \n",
        "        # input -> query\n",
        "        # memory -> key, value\n",
        "        # [batch_size, token_num, hidden_dim] @ [hidden_dim, hidden_dim] -> [batch_size, token_num, hidden_dim] \n",
        "        query = self.query(x)\n",
        "        key = self.key(memory)\n",
        "        value = self.value(memory)\n",
        "        \n",
        "        # ヘッド数に分割する\n",
        "        # 実際はreshapeで次数を1つ増やす\n",
        "        # [batch_size, token_num, hidden_dim] -> [batch_size, head_num, token_num, hidden_dim/head_num]\n",
        "        query = self._split(query)\n",
        "        key = self._split(key)\n",
        "        value = self._split(value)\n",
        "        \n",
        "        # attention\n",
        "        # 入力と同じ形の出力\n",
        "        # context: [batch_size, token_num, hidden_dim]\n",
        "        # score_weightsはEncoderではNoneとする\n",
        "        context, atten_weight = self.atten(query, key, value, attention_mask)\n",
        "        \n",
        "        if return_attention_scores:\n",
        "            return context, atten_weight\n",
        "        else:\n",
        "            return context\n",
        "\n",
        "class FeedForwardNetwork(nn.Module):\n",
        "    '''\n",
        "    Position-wise Feedforward Neural Network\n",
        "    transformer blockで使用される全結合層\n",
        "    '''\n",
        "    def __init__(self, hidden_dim, drop_rate=0.1):\n",
        "        super().__init__()\n",
        "        # 2層構造\n",
        "        # 1層目：チャンネル数を増加させる\n",
        "        self.filter_dense_layer = nn.Linear(hidden_dim, hidden_dim * 4)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        \n",
        "        # 2層目：元のチャンネル数に戻す\n",
        "        self.output_dense_layer = nn.Linear(hidden_dim * 4, hidden_dim)\n",
        "        self.drop = nn.Dropout(drop_rate)\n",
        "\n",
        "    def forward(self, x):\n",
        "        '''\n",
        "        入力と出力で形が変わらない\n",
        "        [batch_size, token_num, hidden_dim]\n",
        "        '''\n",
        "        \n",
        "        # [batch_size, token_num, hidden_dim] -> [batch_size, token_num, 4*hidden_dim]\n",
        "        x = self.filter_dense_layer(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.drop(x)\n",
        "        \n",
        "        # [batch_size, token_num, 4*hidden_dim] -> [batch_size, token_num, hidden_dim]\n",
        "        return self.output_dense_layer(x)\n",
        "\n",
        "class ResidualNormalizationWrapper(nn.Module):\n",
        "    '''\n",
        "    残差接続\n",
        "    output: input + SubLayer(input)\n",
        "    '''\n",
        "    def __init__(self, hidden_dim, layer, drop_rate=0.1):\n",
        "        super().__init__()\n",
        "        self.layer = layer # SubLayer : ここではAttentionかFFN\n",
        "        self.layer_normalization = nn.LayerNorm(hidden_dim)\n",
        "        self.drop = nn.Dropout(drop_rate)\n",
        "\n",
        "    def forward(self, x, memory=None, attention_mask=None, return_attention_scores=False):\n",
        "        \"\"\"\n",
        "        AttentionもFFNも入力と出力で形が変わらない\n",
        "        [batch_size, token_num, hidden_dim]\n",
        "        \"\"\"\n",
        "        \n",
        "        params = {}\n",
        "        if memory is not None:\n",
        "            params['memory'] = memory\n",
        "        if attention_mask is not None:\n",
        "            params['attention_mask'] = attention_mask\n",
        "        if return_attention_scores:\n",
        "            params['return_attention_scores'] = return_attention_scores\n",
        "        \n",
        "        out = self.layer_normalization(x)\n",
        "        if return_attention_scores:\n",
        "            out, attn_weights = self.layer(out,**params)\n",
        "            out = self.drop(out)\n",
        "            return x + out, attn_weights\n",
        "        else:\n",
        "            out = self.layer(out,**params)\n",
        "            out = self.drop(out)\n",
        "            return x + out\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    transformer block : before ->[attention -> FF]-> next\n",
        "    それぞれ残差接続とLayerNormalizationの処理が含まれる\n",
        "    \"\"\"\n",
        "    def __init__(self, token_num, hidden_dim, heads_num, drop_rate=0.1):\n",
        "        \"\"\"\n",
        "        hidden_numはheads_numで割り切れえる値とすること\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.atten = ResidualNormalizationWrapper(\n",
        "            hidden_dim = hidden_dim,\n",
        "            layer = MultiHeadAttention(token_num=token_num, hidden_dim = hidden_dim, heads_num = heads_num, drop_rate = drop_rate),\n",
        "            drop_rate = drop_rate)\n",
        "        \n",
        "        self.ffn = ResidualNormalizationWrapper(\n",
        "            hidden_dim = hidden_dim,\n",
        "            layer = FeedForwardNetwork(hidden_dim = hidden_dim, drop_rate = drop_rate),\n",
        "            drop_rate = drop_rate)\n",
        "    \n",
        "    def forward(self, input, memory=None, attention_mask=None, return_attention_scores=False):\n",
        "        \"\"\"\n",
        "        入力と出力で形式が変わらない\n",
        "        [batch_size, token_num, hidden_dim]\n",
        "        \"\"\"\n",
        "        if return_attention_scores:\n",
        "            x, attn_weights = self.atten(input, memory, attention_mask, return_attention_scores)\n",
        "            x = self.ffn(x)\n",
        "            return x, attn_weights\n",
        "        else:\n",
        "            x = self.atten(input, memory, attention_mask, return_attention_scores)\n",
        "            x = self.ffn(x)\n",
        "            return x\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    '''\n",
        "    TransformerのEncoder\n",
        "    '''\n",
        "    def __init__(\n",
        "            self,\n",
        "            vocab_size, # 単語の総数\n",
        "            hopping_num, # Multi-head Attentionの繰り返し数\n",
        "            heads_num, # Multi-head Attentionのヘッド数\n",
        "            hidden_dim, # Embeddingの次数\n",
        "            token_num, # 系列長(文章中のトークン数)\n",
        "            drop_rate, # ドロップアウトの確率\n",
        "            pretrained_weight=None\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.hopping_num = hopping_num\n",
        "        \n",
        "        # Embedding層\n",
        "        self.token_embedding = TokenEmbedding(vocab_size, hidden_dim, pretrained_weight)\n",
        "        # Position Embedding\n",
        "        self.add_position_embedding = AddPositionalEncoding()\n",
        "        self.input_dropout_layer = nn.Dropout(drop_rate)\n",
        "\n",
        "        # Multi-head Attentionの繰り返し(hopping)のリスト\n",
        "        self.attention_block_list = nn.ModuleList([TransformerBlock(token_num, hidden_dim, heads_num) for _ in range(hopping_num)])\n",
        "        self.output_normalization = nn.LayerNorm(hidden_dim)\n",
        "\n",
        "    def forward(\n",
        "            self,\n",
        "            input,\n",
        "            memory=None,\n",
        "            attention_mask=None,\n",
        "            return_attention_scores=False\n",
        "    ):\n",
        "        '''\n",
        "        input: 入力 [batch_size, length]\n",
        "        memory: 入力 [batch_size, length]\n",
        "        attention_mask: attention weight に適用される mask\n",
        "            [batch_size, 1, q_length, k_length] \n",
        "            pad 等無視する部分が 0 となるようなもの(Decoderで使用)\n",
        "        出力 [batch_size, length, hidden_dim]\n",
        "        '''\n",
        "        # [batch_size, token_num] -> [batch_size, token_num, hidden_dim]\n",
        "        embedded_input = self.token_embedding(input)\n",
        "        # Positional Embedding\n",
        "        embedded_input = self.add_position_embedding(embedded_input)\n",
        "        query = self.input_dropout_layer(embedded_input)\n",
        "        \n",
        "        if return_attention_scores:\n",
        "            # MultiHead Attentionを繰り返し適用\n",
        "            for i in range(self.hopping_num):\n",
        "                query, atten_weights = self.attention_block_list[i](query, memory, attention_mask, return_attention_scores)\n",
        "\n",
        "            # [batch_size, token_num, hidden_dim]\n",
        "            return self.output_normalization(query), atten_weights\n",
        "        else:\n",
        "            # MultiHead Attentionを繰り返し適用\n",
        "            for i in range(self.hopping_num):\n",
        "                query = self.attention_block_list[i](query, memory, attention_mask, return_attention_scores)\n",
        "\n",
        "            # [batch_size, token_num, hidden_dim]\n",
        "            return self.output_normalization(query)\n",
        "\n",
        "class AttentionClassifier(nn.Module):\n",
        "    def __init__(\n",
        "            self,\n",
        "            vocab_size, # 単語の総数\n",
        "            hopping_num, # Multi-head Attentionの繰り返し数\n",
        "            heads_num, # Multi-head Attentionのヘッド数\n",
        "            hidden_dim, # Embeddingの次数\n",
        "            token_num, # 系列長(文章中のトークン数)\n",
        "            drop_rate, # ドロップアウトの確率\n",
        "            NUMLABELS, # クラス数\n",
        "            pretrained_weight=None,\n",
        "            PAD_ID = 1\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.PAD_ID = PAD_ID\n",
        "        \n",
        "        self.encoder = Encoder(vocab_size, hopping_num, heads_num, hidden_dim, token_num, drop_rate, pretrained_weight)\n",
        "        self.dense1 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.act1 = nn.Tanh()\n",
        "        self.dropout1 = nn.Dropout(drop_rate)   \n",
        "        self.final_layer = nn.Linear(hidden_dim, NUMLABELS)\n",
        "        \n",
        "        nn.init.normal_(self.dense1.weight, std=0.02)\n",
        "        nn.init.normal_(self.dense1.bias, std=0)\n",
        "        nn.init.normal_(self.final_layer.weight, std=0.02)\n",
        "        nn.init.normal_(self.final_layer.bias, std=0)\n",
        "\n",
        "    def forward(self, x, return_attention_scores=False):\n",
        "        self_attention_mask=self._create_enc_attention_mask(x)\n",
        "        \n",
        "        # [batch_size, token_num] -> [batch_size, token_num, hidden_dim]\n",
        "        if return_attention_scores:\n",
        "            enc_output, atten_weights = self.encoder(x, attention_mask=self_attention_mask,return_attention_scores=return_attention_scores)\n",
        "        else:\n",
        "            enc_output = self.encoder(x, attention_mask=self_attention_mask,return_attention_scores=return_attention_scores)\n",
        "        \n",
        "        # 文頭の重みを使用 [batch_size, 0, hidden_dim]\n",
        "        # [batch_size, hidden_dim] -> [batch_size, hidden_dim]\n",
        "        enc_output = self.dense1(enc_output[:, 0, :])\n",
        "        enc_output = self.act1(enc_output)\n",
        "        enc_output = self.dropout1(enc_output)\n",
        "        \n",
        "        # [batch_size, hidden_dim] -> [batch_size, NUMLABELS]\n",
        "        final_output = self.final_layer(enc_output)\n",
        "\n",
        "        if return_attention_scores:\n",
        "            return final_output, atten_weights\n",
        "        else:\n",
        "            return final_output\n",
        "    \n",
        "    def _create_enc_attention_mask(self, x):\n",
        "        batch_size, length = x.shape\n",
        "        # マスクする部分を1とする\n",
        "        pad_array = torch.eq(x, self.PAD_ID).to(dtype=torch.int8)  # [batch_size, token_num]\n",
        "        \n",
        "        # shape broadcasting で [batch_size, head_num, token_num, token_num] になる\n",
        "        return pad_array.view([batch_size, 1, 1, length])"
      ],
      "metadata": {
        "id": "4m6X0_iICDpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tfuYwjONCDtF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2GnM7Q0ZCDwg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}