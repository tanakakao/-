{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spatial-fluid",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "wireless-harmony",
   "metadata": {},
   "source": [
    "## 30. 条件付きGAN(CGAN)\n",
    "条件付きGANとは、生成器と識別器にいくつかの追加情報を与えて、条件付きができるように訓練を行う敵対的生成ネットワークである。  \n",
    "追加情報は、ラベルでもタグや言葉でもよいが、ここではラベルを用いる。  \n",
    "CGANの生成器はリアルな画像を生成するだけではなく、ラベルにもマッチしていなければならない。  \n",
    "これを訓練させれば、望みのラベルを与えることでCGANに生成してほしいサンプルの種類を設定することができる。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lightweight-attack",
   "metadata": {},
   "source": [
    "#### CGAN生成器\n",
    "条件を決めるラベルを$y$とする。  \n",
    "生成器はノイズベクトル$z$とラベル$y$を使って偽のサンプル$G(z,y)=x^*|y$を生成する。  \n",
    "偽のサンプルの目的は、識別器から見て与えられたラベルを持つ本物のサンプルとできるだけ近い見た目になることである。  \n",
    "  \n",
    "#### CGAN識別器\n",
    "識別器では、\n",
    "- ラベル付きの本物の組$(x,y)$\n",
    "- 偽物の画像にそれを生成させるためのラベルが付いた組$(x^*|y,y)$\n",
    "\n",
    "を受け取る。  \n",
    "本物のサンプルとラベルの組では、\n",
    "- 本物のサンプルをどう認識するか\n",
    "- マッチする組み合わせをどう認識するか\n",
    "\n",
    "の両方を学習する。  \n",
    "生成器が生成した組では、偽のサンプルとラベルの組を認識して、本物の組とどう区別するかを学習する。  \n",
    "識別器の出力は、  \n",
    "入力が本物で、ラベルとマッチしているかの確信度を示す単一の確率値である。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "short-season",
   "metadata": {},
   "source": [
    "#### 実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "metric-bangkok",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Activation, BatchNormalization, Concatenate, Dense, Embedding, Flatten, Input, Multiply, Reshape, Conv2D, Conv2DTranspose\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "hollow-latino",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows = 28\n",
    "img_cols = 28\n",
    "channels = 1\n",
    "\n",
    "img_shape = (img_rows, img_cols, channels)\n",
    "\n",
    "z_dim = 100\n",
    "\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virtual-economics",
   "metadata": {},
   "source": [
    "#### 生成器\n",
    "1. ラベル$y$(0～9の整数)を取り出し、z_dim次元(ランダムなノイズベクトルの長さと同じ)の密なベクトルに変換する(embedding層)。  \n",
    "2. ラベル埋め込みベクトルを、ノイズベクトル$z$と組み合わせて、複合ベクトルとする(Multiply層)。\n",
    "3. 出来上がったベクトルをCGANの生成器ネットワークに入力して画像を生成する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "constitutional-fraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(z_dim):\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(256 * 7 * 7, input_dim=z_dim))\n",
    "    model.add(Reshape((7, 7, 256)))\n",
    "    \n",
    "    model.add(Conv2DTranspose(128, kernel_size=3, strides=2, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    \n",
    "    model.add(Conv2DTranspose(64, kernel_size=3, strides=1, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    \n",
    "    model.add(Conv2DTranspose(1, kernel_size=3, strides=2, padding='same'))\n",
    "    \n",
    "    model.add(Activation('tanh'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dangerous-issue",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cgan_generator(z_dim):\n",
    "    \n",
    "    z = Input(shape=(z_dim,))\n",
    "    \n",
    "    label = Input(shape=(1,), dtype='int32')\n",
    "    \n",
    "    label_embedding = Embedding(num_classes, z_dim, input_length=1)(label)\n",
    "    label_embedding = Flatten()(label_embedding)\n",
    "    \n",
    "    joined_representation = Multiply()([z, label_embedding])\n",
    "    \n",
    "    generator = build_generator(z_dim)\n",
    "    \n",
    "    conditional_img = generator(joined_representation)\n",
    "    \n",
    "    return Model([z, label], conditional_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bright-anthropology",
   "metadata": {},
   "source": [
    "#### 識別器\n",
    "1. 0から9の整数値であるラベルを取り出し、Embedding層を使って、28×28×1=784の密ベクトルを作る\n",
    "2. これを変形(Reshape)して、28×28×1の次元を持つ画像に変形する\n",
    "3. 変形したラベル埋め込み画像を、対応する入力画像の上に重ねて、28×28×2の複合表現にする。\n",
    "4. 画像とラベルの複合表現を、CGANの識別器ネットワークに入力する(モデルの入力次元を28×28×2とする)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "golden-stroke",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator(img_shape):\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(64, kernel_size=3, strides=2,\n",
    "                     input_shape=(img_shape[0], img_shape[1], img_shape[2]+1),\n",
    "                     padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    \n",
    "    model.add(Conv2D(64, kernel_size=3, strides=2,\n",
    "                     input_shape=img_shape,\n",
    "                     padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    \n",
    "    model.add(Conv2D(128, kernel_size=3, strides=2,\n",
    "                     input_shape=img_shape,\n",
    "                     padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "broadband-idaho",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cgan_discriminator(img_shape):\n",
    "    \n",
    "    img = Input(shape=img_shape)\n",
    "    \n",
    "    label = Input(shape=(1,), dtype='int32')\n",
    "    \n",
    "    label_embedding = Embedding(num_classes, np.prod(img_shape), input_length=1)(label)\n",
    "    label_embedding = Flatten()(label_embedding)\n",
    "    label_embedding = Reshape(img_shape)(label_embedding)\n",
    "    \n",
    "    concatenated = Concatenate(axis=-1)([img, label_embedding])\n",
    "    \n",
    "    discriminator = build_discriminator(img_shape)\n",
    "    \n",
    "    classification = discriminator(concatenated)\n",
    "    \n",
    "    return Model([img, label], classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "positive-aberdeen",
   "metadata": {},
   "source": [
    "#### モデルの構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "strategic-charm",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cgan(generator, discriminator):\n",
    "    \n",
    "    z = Input(shape=(z_dim,))\n",
    "    \n",
    "    label = Input(shape=(1,))\n",
    "    \n",
    "    img = generator([z, label])\n",
    "    \n",
    "    classification = discriminator([img, label])\n",
    "    \n",
    "    # 生成器 -> 識別器と繋がる統合モデル\n",
    "    # G([z, label]) = x*\n",
    "    # D(x*) = 分類結果\n",
    "    model = Model([z, label], classification)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "capital-yesterday",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = build_cgan_discriminator(img_shape)\n",
    "discriminator.compile(loss='binary_crossentropy',\n",
    "                      optimizer=Adam(),\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "generator = build_cgan_generator(z_dim)\n",
    "\n",
    "discriminator.trainable = False\n",
    "\n",
    "cgan = build_cgan(generator, discriminator)\n",
    "cgan.compile(loss='binary_crossentropy',\n",
    "             optimizer=Adam())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twenty-publisher",
   "metadata": {},
   "source": [
    "#### 訓練\n",
    "  \n",
    "For　訓練の各反復ステップ　do  \n",
    "1. 識別器の訓練  \n",
    "　a. N本物のサンプルとそのラベルの組$(x,y)$からなるミニバッチを、ランダムに作る  \n",
    "　b. ミニバッチに対して$D(x,y)$を計算し、逆誤差伝播によって$\\theta^{(D)}$を更新することで二値分類の損失を最小化する  \n",
    "　c. ランダムなノイズベクトル$z$とクラスのラベル$(z,y)$を作り、偽のサンプルからなるミニバッチを作る:$G(z,y)=x^*|y$  \n",
    "　d. ミニバッチに対して$D(x^*|y,y)$を計算し、逆誤差伝播によって$\\theta^{(D)}$を更新することで二値分類の損失を最小化する  \n",
    "2. 生成器の訓練  \n",
    "　a. ランダムなノイズベクトル$z$とクラスのラベル$(z,y)$を作り、偽のサンプルからなるミニバッチを作る:$G(z,y)=x^*|y$  \n",
    "　b. ミニバッチに対して$D(x^*|y,y)$を計算し、逆誤差伝播によって$\\theta^{(D)}$を更新することで二値分類の損失を最大化する  \n",
    "  \n",
    "End　for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electrical-vienna",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "losses = []\n",
    "\n",
    "def train(iterations, batch_size, sample_interval):\n",
    "    \n",
    "    (X_train, y_train), (_,_) = mnist.load_data()\n",
    "    \n",
    "    X_train = X_train/127.5 - 1.\n",
    "    X_train = np.expand_dims(X_train, axis=3)\n",
    "    \n",
    "    real = np.ones((batch_size, 1))\n",
    "    fake = np.zeros((batch_size, 1))\n",
    "    \n",
    "    for iteration in range(iterations):\n",
    "        # --------------------\n",
    "        # 識別器の学習\n",
    "        # --------------------\n",
    "        idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "        imgs, labels = X_train[idx], y_train[idx]\n",
    "        \n",
    "        z = np.random.normal(0, 1, (batch_size, z_dim))\n",
    "        gen_imgs = generator.predict([z, labels])\n",
    "        \n",
    "        d_loss_real = discriminator.train_on_batch([imgs, labels], real)\n",
    "        d_loss_fake = discriminator.train_on_batch([gen_imgs, labels], fake)\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "        \n",
    "        # --------------------\n",
    "        # 生成器の学習\n",
    "        # --------------------\n",
    "        z = np.random.normal(0, 1, (batch_size, z_dim))\n",
    "        \n",
    "        labels = np.random.randint(0, num_classes, batch_size).reshape(-1, 1)\n",
    "        \n",
    "        g_loss = cgan.train_on_batch([z_labels], real)\n",
    "        \n",
    "        if (iteration + 1) % sample_interval == 0:\n",
    "            print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (iteration + 1, d_loss[0], 100*d_loss[1], g_loss))\n",
    "            \n",
    "            losses.append((d_loss[0], g_loss))\n",
    "            accuracies.append(100*d_loss[1])\n",
    "            \n",
    "            sample_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "noticed-screen",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_images(image_grid_rows=2, image_grid_columns=5):\n",
    "    \n",
    "    z = np.random.normal(0, 1, (image_grid_rows * image_grid_columns, z_dim))\n",
    "    \n",
    "    labels = np.arange(0, 10).reshape(-1, 1)\n",
    "    \n",
    "    gen_imgs = generator.predict([z, labels])\n",
    "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "    \n",
    "    fig, axs = plt.subplots(image_grid_rows,\n",
    "                            image_grid_columns,\n",
    "                            figsize=(10, 4),\n",
    "                            sharey=True,\n",
    "                            sharex=True)\n",
    "    cnt = 0\n",
    "    for i in range(image_grid_rows):\n",
    "        for j in range(image_grid_columns):\n",
    "            axs[i, j].imshow(gen_imgs[cnt, :, :, 0], cmap='gray')\n",
    "            axs[i, j].axis('off')\n",
    "            axs[i, j].set_title(\"Digit: %d\" % labels[cnt])\n",
    "            cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polish-surgeon",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 12000\n",
    "batch_size = 32\n",
    "sample_interval = 1000\n",
    "\n",
    "train(iterations, batch_size, sample_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinate-accuracy",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
